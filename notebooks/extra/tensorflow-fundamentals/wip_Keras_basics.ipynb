{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done\n",
    "* Describe Keras\n",
    "* Show how to create a model in Keras\n",
    "\n",
    "### To do\n",
    "* Describe the 3 different ways of creating a model\n",
    "* Save and load weights https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n",
    "* Accessing various parts of the sequential model\n",
    "* Load pre-trained weights\n",
    "\n",
    "### Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Fundamentals\n",
    "**NB:** This notebook needs to download some material. Click `'Kernel'` >> `'Restar & Run All'` now, so that it can download while you read the introduction. (When download is complete click `'Kernel'` >> `'Restar & Clear All'`, and proceed as normal)\n",
    "\n",
    "This notebook serves as a quick introduction to Keras.\n",
    "As with the TF introduction this is very quick, so have a look at the **external resources** in order to get more depth:\n",
    "* [Keras code](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/keras) in the TF github repo. Looking at the code is often the best way to understand what is going on.\n",
    "* https://github.com/fchollet/keras/tree/master/examples\n",
    "* [Keras as a simplified interface to TensorFlow: tutorial](https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html)\n",
    "* [TensorFlow High-Level APIs: Models in a Box (TensorFlow Dev Summit 2017)](https://www.youtube.com/watch?v=t64ortpgS-E) 17 min video\n",
    "* [Integrating Keras & TensorFlow: The Keras workflow, expanded (TensorFlow Dev Summit 2017)](https://www.youtube.com/watch?v=UeheTiBJ0Io) 18 min video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level APIs\n",
    "Pure TF is very verbose, and it is therefore a good idea to use a high-level API of some sort.\n",
    "This simplifies and speeds-up development, reduces the risk of bugs, and generally reduces headache.\n",
    "Another neat benefit is that a lot of best practices (initialization, scoping, etc.) are hard-coded into the functions.\n",
    "\n",
    "There are other high-level APIs than Keras, such as \n",
    "[TFLearn](http://tflearn.org/),\n",
    "[tf.learn](https://www.tensorflow.org/get_started/tflearn) (yes, the names are confusing :( ),\n",
    "[tf.slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim), and\n",
    "[tf.layers](https://www.tensorflow.org/api_docs/python/tf/layers).\n",
    "These are generally intercompatible, and offer overlaping functionality.\n",
    "This can be confusing.\n",
    "In order to simplify things we have chosen to focus on just one: Keras.\n",
    "\n",
    "**[Keras](https://keras.io/)**\n",
    "is a high-level API that can use TensorFlow or Theano as backend.\n",
    "In early 2017 [TensorFlow chose Keras](http://www.fast.ai/2017/01/03/keras/) as the first high-level API to include into the tensorflow core (as opposed to contrib).\n",
    "Keras has official Google support and has a large community and pre-existing examples.\n",
    "Making it the best high-level API to learn at the moment (according to the author).\n",
    "\n",
    "Keras sits of top of TFLayers, and shares its implementation (e.g. `tf.layers.dense` and `keras.layers.Dense` are the same).\n",
    "Keras helps with model creation, training, and evaluation.\n",
    "We won't use Keras to its full potential in this course, as it sometimes encapsulates the details to such an extent that it hinders learning.\n",
    "\n",
    "![](keras_overview.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Basic Example\n",
    "\n",
    "Keras can be accessed either as a stand alone library (that can use different backends), or through TF.\n",
    "This only affects the import statements, and porting code back and forth should be very simple.\n",
    "We will access Keras through TF, in order to ensure that the versions are fully compatible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join('.', '..')) \n",
    "import utils\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.contrib.keras as keras\n",
    "from tensorflow.contrib.keras import backend as K\n",
    "from tensorflow.contrib.keras.api.keras.models import Sequential, Model\n",
    "from tensorflow.contrib.keras.api.keras.layers import Dense, Input\n",
    "from tensorflow.contrib.keras.api.keras.losses import categorical_crossentropy\n",
    "from tensorflow.contrib.keras.api.keras.metrics \\\n",
    "    import categorical_accuracy\n",
    "\n",
    "if int(tf.__version__[0]) < 1:\n",
    "    print('WARNING: This will probably not work with TF version < 1.0')\n",
    "    print('Your version is ' + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple ways of solving MNIST\n",
    "\n",
    "Keras kan be used in several ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create training loop\n",
    "max_epoch = 101\n",
    "batch_size = 64\n",
    "def train(train_op, acc_value):\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    with tf.Session().as_default() as sess:\n",
    "        # Tell Keras to use the session to initialize all variables that it \n",
    "        # creates internally\n",
    "        K.set_session(sess)\n",
    "        sess.run(init_op)\n",
    "\n",
    "        for i in range(max_epoch):\n",
    "            batch = mnist_data.train.next_batch(batch_size)\n",
    "            train_op.run(feed_dict={img:batch[0], labels:batch[1]})\n",
    "            if i % 10 == 0:\n",
    "                accuracy = acc_value.eval(feed_dict={img: mnist_data.test.images,\n",
    "                                    labels: mnist_data.test.labels})\n",
    "                print ('{:3} : {:.3}'.format(i, accuracy))\n",
    "    graph = utils.rename_nodes(sess.graph_def, lambda s:\"/\".join(s.split('_',1)))\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load data (download if you haven't already)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "method = 3\n",
    "print('Method ' + str(method))\n",
    "\n",
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Prepare placeholders\n",
    "img = tf.placeholder(tf.float32, shape=(None, 784), name='img')\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 10), name='label')\n",
    "\n",
    "if method == 1:\n",
    "    # Easy\n",
    "    # Saving weights is hard\n",
    "    # A lot of control\n",
    "    with tf.name_scope('model'):\n",
    "        x = Dense(128, activation='relu', name='Dense1')(img)\n",
    "        x = Dense(128, activation='relu', name='Dense2')(x)\n",
    "    preds = Dense(10, activation='softmax', name='prediction')(x)\n",
    "\n",
    "elif method == 2:\n",
    "    # Easy\n",
    "    # saving weights is easy\n",
    "    # Loss of control (ugly TB graph)\n",
    "    with tf.name_scope('model'):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, activation='relu', name='Dense1', input_dim=784)) \n",
    "        model.add(Dense(128, activation='relu', name='Dense2'))\n",
    "    model.add(Dense(10, activation='softmax', name='prediction'))\n",
    "    preds = model(img)\n",
    "    \n",
    "elif method == 3:\n",
    "    # A bit less easy\n",
    "    # Saving weights is easy\n",
    "    # A lot of control    \n",
    "    # Essentially method 1, wraped in a a model (similar to method 2)\n",
    "    # Allows you to access intermediate layers: https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
    "        with tf.name_scope('model'):\n",
    "            input_layer = Input(tensor=img)\n",
    "            x = Dense(128, activation='relu', name='Dense1')(input_layer)\n",
    "            x = Dense(128, activation='relu', name='Dense2')(x)\n",
    "        x = Dense(10, activation='softmax', name='prediction')(x)\n",
    "\n",
    "        model = Model(inputs=input_layer, outputs=x)\n",
    "        preds = model.output\n",
    "else:\n",
    "    print('{} is not a valid method argument!'.format(method))\n",
    "\n",
    "    \n",
    "## Create ops\n",
    "with tf.name_scope('accuracy'):\n",
    "    acc_value = K.mean(categorical_accuracy(labels, preds))\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(categorical_crossentropy(labels, preds))\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5)          \n",
    "    train_op = optimizer.minimize(loss)\n",
    "\n",
    "## Run training loop, and return the graph\n",
    "graph = train(train_op, acc_value)\n",
    "\n",
    "## Launch TensorBoard, and visualize the TF graph\n",
    "utils.show_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the cool things about Keras is that it makes it very easy to use pretrained models!\n",
    "\n",
    "Read more about [using pretrained models with Keras](https://keras.io/applications/)\n",
    "\n",
    "22 million parameters\n",
    "\n",
    "[Inception in TF](https://github.com/tensorflow/models/tree/master/inception)\n",
    "\n",
    "Code: [inception_v3.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/keras/python/keras/applications/inception_v3.py). How it is implemented in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## RUN THIS CELL ASAP! It takes a while to complete!\n",
    "## The cell downloads the weights (~80 mb), if they aren't already.\n",
    "\n",
    "# Create a \n",
    "inception_stem = tf.contrib.keras.applications.InceptionV3(\n",
    "    weights='imagenet',\n",
    "    include_top=False, # Don't include the dense layers on top of the network\n",
    "    input_shape=None, # width and height should be no smaller than 139\n",
    "#     pool='avg'\n",
    ")\n",
    "\n",
    "# Initially we don't want to change \n",
    "inception_stem.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Try and \n",
    "# inception_stem.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Credits\n",
    "Created by Toke Faurby ([faur](https://github.com/Faur)).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
