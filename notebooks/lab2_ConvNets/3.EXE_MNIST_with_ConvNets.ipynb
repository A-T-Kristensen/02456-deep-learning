{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with ConvNets\n",
    "\n",
    "> <span style=\"color:gray\">\n",
    "Original [Theano/Lasagne tutorial](https://github.com/DeepLearningDTU/nvidia_deep_learning_summercamp_2016/blob/master/lab1/lab1_FFN.ipynb) by \n",
    "Lars Maaløe ([larsmaaloee](https://github.com/larsmaaloee)),\n",
    "Søren Kaae Sønderby ([skaae](https://github.com/skaae)), and \n",
    "Casper Sønderby ([casperkaae](https://github.com/casperkaae)). \n",
    "Converted to TensorFlow by \n",
    "Alexander R. Johansen ([alrojo](https://github.com/alrojo)), \n",
    "and updated by \n",
    "Toke Faurby ([faur](https://github.com/Faur)).\n",
    "</span>\n",
    "\n",
    "\n",
    "In this lab we will solve the MNIST problem again, but this time with convolutional networks.\n",
    "You will get a to try stacking of convolutional layers, max pooling and strided convolutions which are all important techniques in current convolutional layers network architectures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependancies and supporting functions\n",
    "\n",
    "\n",
    "Loading dependancies and supporting functions by running the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import sklearn.datasets\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join('.', '..')) \n",
    "import utils \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.contrib.layers import flatten # We use this flatten, as it works better than \n",
    "                                              # the Keras 'Flatten' for some reason\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred(X_in, sess):\n",
    "    # first we must define what data to give it\n",
    "    feed_dict = {x_pl: X_in}\n",
    "    # secondly our fetches\n",
    "    fetches = [y]\n",
    "    # utilizing the given session (ref. sess) to compute results\n",
    "    res = sess.run(fetches, feed_dict)\n",
    "    # res is a list with each indices representing the corresponding element in fetches\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST data set\n",
    "\n",
    "We load the MNIST dataset.\n",
    "This time the data is keept as images (`shape = [28, 28, 1]`), and not flattended into vectors (`shape = [784]`).\n",
    "This allows the convolutional network to take advantage of the structure of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Information on dataset\n",
      "    ----------------------\n",
      "Training size:\t 55000\n",
      "Test size\t 10000\n",
      "Validation size\t 5000\n",
      "\n",
      "Data summaries\n",
      "Image shape\t\t (28, 28, 1)\n",
      "Image type\t\t <class 'numpy.ndarray'>\n",
      "Image min/max value\t 0.0 / 1.0\n",
      "Label shape\t\t (10,)\n",
      "Label type\t\t <class 'numpy.float64'>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAEICAYAAABWCOFPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCgoKCiYoo6CgoGDC/wPG7l7oloY3bwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x231331a2080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data (download if you haven't already)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', \n",
    "                                       one_hot=True,   # Convert the labels into one hot encoding\n",
    "                                       dtype='float32', # rescale images to `[0, 1]`\n",
    "                                       reshape=False, # Don't flatten the images to vectors\n",
    "                                      )\n",
    "## Print dataset statistics and visualize\n",
    "print('')\n",
    "utils.mnist_summary(mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.45)\n",
    "\n",
    "num_classes = 10\n",
    "height, width, nchannels = 28, 28, 1\n",
    "padding = 'same'\n",
    "\n",
    "batch_size = 100\n",
    "max_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "We will use Keras layers, which are documented [here](https://keras.io/layers/about-keras-layers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace of the tensors shape as it is propagated through the network.\n",
      "Layer name \t Output size\n",
      "----------------------------\n",
      "x_pl \t\t (?, 28, 28, 1)\n",
      "conv1 \t\t (?, 28, 28, 16)\n",
      "pool1 \t\t (?, 14, 14, 16)\n",
      "Flatten \t (?, 3136)\n",
      "denseOut\t (?, 10)\n",
      "Model consits of  31786 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "filters_1 = 16\n",
    "kernel_size_1 = (5,5)\n",
    "pool_size_1 = (2,2)\n",
    "\n",
    "x_pl = tf.placeholder(tf.float32, [None, height, width, nchannels], name='xPlaceholder')\n",
    "y_pl = tf.placeholder(tf.float64, [None, num_classes], name='yPlaceholder')\n",
    "y_pl = tf.cast(y_pl, tf.float32)\n",
    "\n",
    "print('Trace of the tensors shape as it is propagated through the network.')\n",
    "print('Layer name \\t Output size')\n",
    "print('----------------------------')\n",
    "\n",
    "with tf.variable_scope('convLayer1'):\n",
    "    conv1 = Conv2D(filters_1, kernel_size_1, strides=(1,1), padding=padding, activation='relu')\n",
    "    print('x_pl \\t\\t', x_pl.get_shape())\n",
    "    x = conv1(x_pl)\n",
    "    print('conv1 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=pool_size_1, strides=None, padding=padding)\n",
    "    x = pool1(x)\n",
    "    print('pool1 \\t\\t', x.get_shape())\n",
    "    x = flatten(x)\n",
    "    print('Flatten \\t', x.get_shape())\n",
    "\n",
    "with tf.variable_scope('output_layer'):\n",
    "    denseOut = Dense(units=num_classes, activation='softmax')\n",
    "\n",
    "    y = denseOut(x)\n",
    "    print('denseOut\\t', y.get_shape())    \n",
    "\n",
    "print('Model consits of ', utils.num_params(), 'trainable parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    # computing cross entropy per sample\n",
    "    cross_entropy = -tf.reduce_sum(y_pl * tf.log(y+1e-8), reduction_indices=[1])\n",
    "\n",
    "    # averaging over samples\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "with tf.variable_scope('training'):\n",
    "    # defining our optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "    # applying the gradients\n",
    "    train_op = optimizer.minimize(cross_entropy)\n",
    "\n",
    "with tf.variable_scope('performance'):\n",
    "    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n",
    "    correct_prediction = tf.equal(tf.argmax(y, axis=1), tf.argmax(y_pl, axis=1))\n",
    "\n",
    "    # averaging the one-hot encoded vector\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.24241406532567455&quot;).pbtxt = 'node {\\n  name: &quot;xPlaceholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 28\\n        }\\n        dim {\\n          size: 28\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;yPlaceholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;yPlaceholder&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.11881770193576813\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.11881770193576813\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 87654321\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 2502494\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/max&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/RandomUniform&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/mul&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;convLayer1/conv2d/1/kernel&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;convLayer1/conv2d/1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;convLayer1/conv2d/1/bias&quot;\\n  input: &quot;convLayer1/conv2d/1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;convLayer1/conv2d/1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/convolution/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/convolution/dilation_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/convolution&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;xPlaceholder&quot;\\n  input: &quot;convLayer1/conv2d/1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;convLayer1/conv2d/1/convolution&quot;\\n  input: &quot;convLayer1/conv2d/1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;convLayer1/conv2d/1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/max/pooling2d_1/MaxPool&quot;\\n  op: &quot;MaxPool&quot;\\n  input: &quot;convLayer1/conv2d/1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;convLayer1/max/pooling2d_1/MaxPool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Slice/begin&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Slice/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;convLayer1/Flatten/Shape&quot;\\n  input: &quot;convLayer1/Flatten/Slice/begin&quot;\\n  input: &quot;convLayer1/Flatten/Slice/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Slice/1/begin&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Slice/1/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Slice/1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;convLayer1/Flatten/Shape&quot;\\n  input: &quot;convLayer1/Flatten/Slice/1/begin&quot;\\n  input: &quot;convLayer1/Flatten/Slice/1/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;convLayer1/Flatten/Slice/1&quot;\\n  input: &quot;convLayer1/Flatten/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;convLayer1/Flatten/Prod&quot;\\n  input: &quot;convLayer1/Flatten/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;convLayer1/Flatten/Slice&quot;\\n  input: &quot;convLayer1/Flatten/ExpandDims&quot;\\n  input: &quot;convLayer1/Flatten/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;convLayer1/max/pooling2d_1/MaxPool&quot;\\n  input: &quot;convLayer1/Flatten/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;@\\\\014\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.04367131367325783\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.04367131367325783\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 87654321\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 447393\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/max&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/RandomUniform&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/mul&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3136\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;output/layer/dense_1/kernel&quot;\\n  input: &quot;output/layer/dense_1/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;output/layer/dense_1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;output/layer/dense_1/bias&quot;\\n  input: &quot;output/layer/dense_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;output/layer/dense_1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;convLayer1/Flatten/Reshape&quot;\\n  input: &quot;output/layer/dense_1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;output/layer/dense_1/MatMul&quot;\\n  input: &quot;output/layer/dense_1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/Softmax&quot;\\n  op: &quot;Softmax&quot;\\n  input: &quot;output/layer/dense_1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999993922529e-09\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;output/layer/dense_1/Softmax&quot;\\n  input: &quot;loss/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;loss/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cast&quot;\\n  input: &quot;loss/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Sum/reduction/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;loss/mul&quot;\\n  input: &quot;loss/Sum/reduction/indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;loss/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/Neg&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;training/gradients/Shape&quot;\\n  input: &quot;training/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/Fill&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/Neg&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Reshape&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/Neg&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Shape_1&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Shape_2&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Prod_1&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Prod&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Tile&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Neg/grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss/Sum/reduction/indices&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/add&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/range/start&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Size&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Shape_1&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/range&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/mod&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Shape&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/DynamicStitch&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Shape&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/loss/Neg/grad/Neg&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Reshape&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Shape&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Tile&quot;\\n  input: &quot;loss/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/gradients/loss/mul/grad/mul&quot;\\n  input: &quot;training/gradients/loss/mul/grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Sum&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cast&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/gradients/loss/mul/grad/mul_1&quot;\\n  input: &quot;training/gradients/loss/mul/grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Sum_1&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/gradients/loss/mul/grad/Reshape&quot;\\n  input: &quot;^training/gradients/loss/mul/grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Reshape&quot;\\n  input: &quot;^training/gradients/loss/mul/grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/loss/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Reshape_1&quot;\\n  input: &quot;^training/gradients/loss/mul/grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/loss/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Log/grad/Reciprocal&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;loss/add&quot;\\n  input: &quot;^training/gradients/loss/mul/grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Log/grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/gradients/loss/mul/grad/tuple/control_dependency_1&quot;\\n  input: &quot;training/gradients/loss/Log/grad/Reciprocal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;output/layer/dense_1/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;training/gradients/loss/add/grad/Shape&quot;\\n  input: &quot;training/gradients/loss/add/grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/gradients/loss/Log/grad/mul&quot;\\n  input: &quot;training/gradients/loss/add/grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/loss/add/grad/Sum&quot;\\n  input: &quot;training/gradients/loss/add/grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/gradients/loss/Log/grad/mul&quot;\\n  input: &quot;training/gradients/loss/add/grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/loss/add/grad/Sum_1&quot;\\n  input: &quot;training/gradients/loss/add/grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/gradients/loss/add/grad/Reshape&quot;\\n  input: &quot;^training/gradients/loss/add/grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/loss/add/grad/Reshape&quot;\\n  input: &quot;^training/gradients/loss/add/grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/loss/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/loss/add/grad/Reshape_1&quot;\\n  input: &quot;^training/gradients/loss/add/grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/loss/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/gradients/loss/add/grad/tuple/control_dependency&quot;\\n  input: &quot;output/layer/dense_1/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/mul&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Sum&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;training/gradients/loss/add/grad/tuple/control_dependency&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/sub&quot;\\n  input: &quot;output/layer/dense_1/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/Softmax_grad/mul_1&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/mul_1&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/output_layer/dense_1/Softmax_grad/mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/output_layer/dense_1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;output/layer/dense_1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;convLayer1/Flatten/Reshape&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/output_layer/dense_1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/output_layer/dense_1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/Flatten/Reshape/grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;convLayer1/max/pooling2d_1/MaxPool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/Flatten/Reshape/grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;training/gradients/convLayer1/Flatten/Reshape/grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/max/pooling2d_1/MaxPool_grad/MaxPoolGrad&quot;\\n  op: &quot;MaxPoolGrad&quot;\\n  input: &quot;convLayer1/conv2d/1/Relu&quot;\\n  input: &quot;convLayer1/max/pooling2d_1/MaxPool&quot;\\n  input: &quot;training/gradients/convLayer1/Flatten/Reshape/grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;training/gradients/convLayer1/max/pooling2d_1/MaxPool_grad/MaxPoolGrad&quot;\\n  input: &quot;convLayer1/conv2d/1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/convLayer1/conv2d_1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/convLayer1/conv2d_1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;xPlaceholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Shape&quot;\\n  input: &quot;convLayer1/conv2d/1/kernel/read&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;xPlaceholder&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Shape_1&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/convolution_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/convolution_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/convolution_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/convLayer1/conv2d_1/convolution_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/convolution_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/convLayer1/conv2d_1/convolution_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta1/power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta1/power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta1/power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/beta1/power&quot;\\n  input: &quot;training/beta1/power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta1/power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/beta1/power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta2/power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.9990000128746033\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta2/power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta2/power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/beta2/power&quot;\\n  input: &quot;training/beta2/power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta2/power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/beta2/power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam_1&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam_1&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3136\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3136\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3136\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3136\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam_1&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam_1&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/learning/rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/beta1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/beta2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.9990000128746033\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/epsilon&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999993922529e-09\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/update/convLayer1/conv2d_1/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;convLayer1/conv2d/1/kernel&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam_1&quot;\\n  input: &quot;training/beta1/power/read&quot;\\n  input: &quot;training/beta2/power/read&quot;\\n  input: &quot;training/Adam/learning/rate&quot;\\n  input: &quot;training/Adam/beta1&quot;\\n  input: &quot;training/Adam/beta2&quot;\\n  input: &quot;training/Adam/epsilon&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/update/convLayer1/conv2d_1/bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;convLayer1/conv2d/1/bias&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam_1&quot;\\n  input: &quot;training/beta1/power/read&quot;\\n  input: &quot;training/beta2/power/read&quot;\\n  input: &quot;training/Adam/learning/rate&quot;\\n  input: &quot;training/Adam/beta1&quot;\\n  input: &quot;training/Adam/beta2&quot;\\n  input: &quot;training/Adam/epsilon&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/update/output_layer/dense_1/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;output/layer/dense_1/kernel&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam_1&quot;\\n  input: &quot;training/beta1/power/read&quot;\\n  input: &quot;training/beta2/power/read&quot;\\n  input: &quot;training/Adam/learning/rate&quot;\\n  input: &quot;training/Adam/beta1&quot;\\n  input: &quot;training/Adam/beta2&quot;\\n  input: &quot;training/Adam/epsilon&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/update/output_layer/dense_1/bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;output/layer/dense_1/bias&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam_1&quot;\\n  input: &quot;training/beta1/power/read&quot;\\n  input: &quot;training/beta2/power/read&quot;\\n  input: &quot;training/Adam/learning/rate&quot;\\n  input: &quot;training/Adam/beta1&quot;\\n  input: &quot;training/Adam/beta2&quot;\\n  input: &quot;training/Adam/epsilon&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/beta1/power/read&quot;\\n  input: &quot;training/Adam/beta1&quot;\\n  input: &quot;^training/Adam/update/convLayer1/conv2d_1/kernel/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/convLayer1/conv2d_1/bias/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/output_layer/dense_1/kernel/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/output_layer/dense_1/bias/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/beta1/power&quot;\\n  input: &quot;training/Adam/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/mul/1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/beta2/power/read&quot;\\n  input: &quot;training/Adam/beta2&quot;\\n  input: &quot;^training/Adam/update/convLayer1/conv2d_1/kernel/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/convLayer1/conv2d_1/bias/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/output_layer/dense_1/kernel/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/output_layer/dense_1/bias/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/Assign/1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/beta2/power&quot;\\n  input: &quot;training/Adam/mul/1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/Adam/update/convLayer1/conv2d_1/kernel/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/convLayer1/conv2d_1/bias/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/output_layer/dense_1/kernel/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/output_layer/dense_1/bias/ApplyAdam&quot;\\n  input: &quot;^training/Adam/Assign&quot;\\n  input: &quot;^training/Adam/Assign/1&quot;\\n}\\nnode {\\n  name: &quot;performance/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;output/layer/dense_1/Softmax&quot;\\n  input: &quot;performance/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/ArgMax/1/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/ArgMax/1&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;Cast&quot;\\n  input: &quot;performance/ArgMax/1/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;performance/ArgMax&quot;\\n  input: &quot;performance/ArgMax/1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;performance/Equal&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;performance/Cast&quot;\\n  input: &quot;performance/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.24241406532567455&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Launch TensorBoard, and visualize the TF graph\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    tmp_def = utils.rename_nodes(sess.graph_def, lambda s:\"/\".join(s.split('_',1)))\n",
    "    utils.show_graph(tmp_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "#Test the forward pass\n",
    "x_batch, y_batch = mnist_data.train.next_batch(4)\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "# with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    y_pred = sess.run(fetches=y, feed_dict={x_pl: x_batch})\n",
    "\n",
    "assert y_pred.shape == y_batch.shape, \"ERROR the output shape is not as expected!\" \\\n",
    "        + \" Output shape should be \" + str(y.shape) + ' but was ' + str(y_pred.shape)\n",
    "\n",
    "print('Forward pass successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training loop\n",
      "Epoch 1 : Train Loss  0.147, Train acc  0.950,  Valid loss  0.136,  Valid acc  0.962\n",
      "Epoch 2 : Train Loss  0.115, Train acc  0.950,  Valid loss  0.092,  Valid acc  0.974\n",
      "Epoch 3 : Train Loss  0.049, Train acc  0.990,  Valid loss  0.074,  Valid acc  0.977\n",
      "Epoch 4 : Train Loss  0.022, Train acc  1.000,  Valid loss  0.066,  Valid acc  0.980\n",
      "Epoch 5 : Train Loss  0.027, Train acc  0.990,  Valid loss  0.058,  Valid acc  0.983\n",
      "Epoch 6 : Train Loss  0.013, Train acc  1.000,  Valid loss  0.055,  Valid acc  0.984\n",
      "Epoch 7 : Train Loss  0.020, Train acc  1.000,  Valid loss  0.056,  Valid acc  0.983\n",
      "Epoch 8 : Train Loss  0.136, Train acc  0.970,  Valid loss  0.053,  Valid acc  0.985\n",
      "Epoch 9 : Train Loss  0.015, Train acc  1.000,  Valid loss  0.053,  Valid acc  0.985\n",
      "Epoch 10 : Train Loss  0.043, Train acc  0.980,  Valid loss  0.052,  Valid acc  0.987\n",
      "Test Loss  0.048, Test acc  0.986\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "valid_loss, valid_accuracy = [], []\n",
    "train_loss, train_accuracy = [], []\n",
    "test_loss, test_accuracy = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Begin training loop')\n",
    "\n",
    "    try:\n",
    "        while mnist_data.train.epochs_completed < max_epochs:\n",
    "            _train_loss, _train_accuracy = [], []\n",
    "            \n",
    "            ## Run train op\n",
    "            x_batch, y_batch = mnist_data.train.next_batch(batch_size)\n",
    "            fetches_train = [train_op, cross_entropy, accuracy]\n",
    "            feed_dict_train = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _, _loss, _acc = sess.run(fetches_train, feed_dict_train)\n",
    "            \n",
    "            _train_loss.append(_loss)\n",
    "            _train_accuracy.append(_acc)\n",
    "            \n",
    "            ## Compute validation loss and accuracy\n",
    "            if mnist_data.train.epochs_completed % 1 == 0 \\\n",
    "                    and mnist_data.train._index_in_epoch <= batch_size:\n",
    "                train_loss.append(np.mean(_train_loss))\n",
    "                train_accuracy.append(np.mean(_train_accuracy))\n",
    "\n",
    "                fetches_valid = [cross_entropy, accuracy]\n",
    "                \n",
    "                feed_dict_valid = {x_pl: mnist_data.validation.images, y_pl: mnist_data.validation.labels}\n",
    "                _loss, _acc = sess.run(fetches_valid, feed_dict_valid)\n",
    "                \n",
    "                valid_loss.append(_loss)\n",
    "                valid_accuracy.append(_acc)\n",
    "                print(\"Epoch {} : Train Loss {:6.3f}, Train acc {:6.3f},  Valid loss {:6.3f},  Valid acc {:6.3f}\".format(\n",
    "                    mnist_data.train.epochs_completed, train_loss[-1], train_accuracy[-1], valid_loss[-1], valid_accuracy[-1]))\n",
    "        \n",
    "        test_epoch = mnist_data.test.epochs_completed\n",
    "        while mnist_data.test.epochs_completed == test_epoch:\n",
    "            x_batch, y_batch = mnist_data.test.next_batch(batch_size)\n",
    "            feed_dict_test = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _loss, _acc = sess.run(fetches_valid, feed_dict_test)\n",
    "            test_loss.append(_loss)\n",
    "            test_accuracy.append(_acc)\n",
    "        print('Test Loss {:6.3f}, Test acc {:6.3f}'.format(\n",
    "                    np.mean(test_loss), np.mean(test_accuracy)))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.text.Text at 0x231370b0d30>,\n",
       " <matplotlib.text.Text at 0x23134d4f908>,\n",
       " (0.75, 1.03))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0YIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2313709db70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = np.arange(len(train_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_accuracy,'r', epoch, valid_accuracy,'b')\n",
    "plt.legend(['Train Acc','Val Acc'], loc=4)\n",
    "plt.xlabel('Epochs'), plt.ylabel('Acc'), plt.ylim([0.75,1.03])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> EXE 1.1 </span> Manual calculations\n",
    "\n",
    "![](images/conv_exe.png)\n",
    "\n",
    "\n",
    "\n",
    "1. Manually convolve the input, and compute the convolved features. No padding and no strieds.\n",
    "1. Perform `2x2` max pooling on the convolved features. Stride of 2.\n",
    "\n",
    "___\n",
    "\n",
    "<span style=\"color:blue\"> Answer: </span>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We just place the kernel matrix on top of the pixels and multiply, just as shown in the first notebook from week 2.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    y_{0,0} &= 1 \\cdot 2 +2 \\cdot 3 = 8 \\\\\n",
    "    y_{1,0} &= 2 \\cdot 1 + 2 \\cdot 1 + 2 \\cdot 2 + 2 \\cdot 3 = 14 \\\\\n",
    "    y_{0,1} &= 2 \\cdot 2 + 2 \\cdot 2 + 3 \\cdot 3 + 1 \\cdot 1 + 2 \\cdot 2 = 20 \\\\\n",
    "    y_{1,1} &= 2 \\cdot 2 + 2 \\cdot 1 + 2 \\cdot 2 + 3 \\cdot 2 + 3 \\cdot 3 = 25\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We can verify the result with scipy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8 20]\n",
      " [14 25]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 0, 0, 1],[0, 0,1,2],[0,0,2,3],[0,1,2,3]])\n",
    "k=np.array([[0,0,2],[0,1,2],[0,2,3]])\n",
    "k = np.rot90(k, 2)\n",
    "y = signal.convolve2d(x, k, 'valid')\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Performing 2x2 max pooling on a 2x2 matrix will just give us 25, even with a stride of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:red\"> EXE 1.2 </span> Reducing the resolution\n",
    "One of the important features of convolutional networks are their ability to reduce the spatial resolution, while retaining the important features.\n",
    "Effectively this gives a local translational invariance and reduces the computation. \n",
    "This is most often done with **maxpooling** or by using strides.\n",
    "\n",
    "1. Using only convolutional layers and pooling operations reduce the feature map size to `1x1xF`.\n",
    "    * The number of feature maps, `F`, is up to you.\n",
    "\n",
    "___\n",
    "\n",
    "<span style=\"color:blue\"> Write down what you did: </span>\n",
    "\n",
    "``` \n",
    "Paste your code here\n",
    "```\n",
    "\n",
    "\n",
    "``` \n",
    "Paste the trace of the tensors shape as it is propagated through the network here\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">I need to import this again, otherwise the training will fail.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', \n",
    "                                       one_hot=True,   # Convert the labels into one hot encoding\n",
    "                                       dtype='float32', # rescale images to `[0, 1]`\n",
    "                                       reshape=False, # Don't flatten the images to vectors\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">I define the network</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace of the tensors shape as it is propagated through the network.\n",
      "Layer name \t Output size\n",
      "----------------------------\n",
      "x_pl \t\t (?, 28, 28, 1)\n",
      "conv1 \t\t (?, 28, 28, 32)\n",
      "pool1 \t\t (?, 14, 14, 32)\n",
      "conv2 \t\t (?, 14, 14, 64)\n",
      "pool2 \t\t (?, 7, 7, 64)\n",
      "conv3 \t\t (?, 7, 7, 14)\n",
      "pool3 \t\t (?, 1, 1, 14)\n",
      "Flatten \t (?, 14)\n",
      "denseOut\t (?, 10)\n",
      "Model consits of  27044 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "filters_1 = 32\n",
    "kernel_size_1 = (3,3)\n",
    "pool_size_1 = (2,2)\n",
    "\n",
    "filters_2 = 64\n",
    "kernel_size_2 = (3,3)\n",
    "pool_size_2 = (2, 2)\n",
    "\n",
    "filters_3 = 14\n",
    "kernel_size_3 = (3,3)\n",
    "pool_size_3 = (7, 7)\n",
    "\n",
    "x_pl = tf.placeholder(tf.float32, [None, height, width, nchannels], name='xPlaceholder')\n",
    "y_pl = tf.placeholder(tf.float64, [None, num_classes], name='yPlaceholder')\n",
    "y_pl = tf.cast(y_pl, tf.float32)\n",
    "\n",
    "print('Trace of the tensors shape as it is propagated through the network.')\n",
    "print('Layer name \\t Output size')\n",
    "print('----------------------------')\n",
    "\n",
    "with tf.variable_scope('convLayer1'):\n",
    "    conv1 = Conv2D(filters_1, kernel_size_1, strides=(1,1), padding=padding, activation='relu')\n",
    "    print('x_pl \\t\\t', x_pl.get_shape())\n",
    "    x = conv1(x_pl)\n",
    "    print('conv1 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=pool_size_1, strides=None, padding=padding)\n",
    "    x = pool1(x)\n",
    "    print('pool1 \\t\\t', x.get_shape())\n",
    "\n",
    "with tf.variable_scope('convLayer2'):\n",
    "    conv2 = Conv2D(filters_2, kernel_size_2, strides=(1,1), padding=padding, activation='relu')\n",
    "    x = conv2(x)\n",
    "    print('conv2 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=pool_size_2, strides=None, padding=padding)\n",
    "    x = pool2(x)\n",
    "    print('pool2 \\t\\t', x.get_shape())\n",
    "    \n",
    "with tf.variable_scope('convLayer3'):\n",
    "    conv3 = Conv2D(filters_3, kernel_size_3, strides=(1,1), padding=padding, activation='relu')\n",
    "    x = conv3(x)\n",
    "    print('conv3 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool3 = MaxPooling2D(pool_size=pool_size_3, strides=None, padding=padding)\n",
    "    x = pool3(x)\n",
    "    print('pool3 \\t\\t', x.get_shape())\n",
    "\n",
    "    x = flatten(x)\n",
    "    print('Flatten \\t', x.get_shape())     \n",
    "\n",
    "with tf.variable_scope('output_layer'):\n",
    "    denseOut = Dense(units=num_classes, activation='softmax')\n",
    "\n",
    "    y = denseOut(x)\n",
    "    print('denseOut\\t', y.get_shape())    \n",
    "\n",
    "print('Model consits of ', utils.num_params(), 'trainable parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">To get 1x1xF, I just maxpool 7x7 (size of what we have before)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    # computing cross entropy per sample\n",
    "    cross_entropy = -tf.reduce_sum(y_pl * tf.log(y+1e-8), reduction_indices=[1])\n",
    "\n",
    "    # averaging over samples\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "with tf.variable_scope('training'):\n",
    "    # defining our optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "    # applying the gradients\n",
    "    train_op = optimizer.minimize(cross_entropy)\n",
    "\n",
    "with tf.variable_scope('performance'):\n",
    "    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n",
    "    correct_prediction = tf.equal(tf.argmax(y, axis=1), tf.argmax(y_pl, axis=1))\n",
    "\n",
    "    # averaging the one-hot encoded vector\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Add saver op to restore the model for prediction  \n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training loop\n",
      "Epoch 0 : Train Loss  2.314, Train acc  0.040,  Valid loss  2.298,  Valid acc  0.119\n",
      "Epoch 1 : Train Loss  0.125, Train acc  0.940,  Valid loss  0.189,  Valid acc  0.948\n",
      "Epoch 2 : Train Loss  0.149, Train acc  0.970,  Valid loss  0.146,  Valid acc  0.955\n",
      "Epoch 3 : Train Loss  0.034, Train acc  0.990,  Valid loss  0.102,  Valid acc  0.972\n",
      "Epoch 4 : Train Loss  0.037, Train acc  0.990,  Valid loss  0.114,  Valid acc  0.967\n",
      "Epoch 5 : Train Loss  0.073, Train acc  0.980,  Valid loss  0.078,  Valid acc  0.976\n",
      "Epoch 6 : Train Loss  0.036, Train acc  0.990,  Valid loss  0.066,  Valid acc  0.980\n",
      "Epoch 7 : Train Loss  0.008, Train acc  1.000,  Valid loss  0.080,  Valid acc  0.977\n",
      "Epoch 8 : Train Loss  0.020, Train acc  1.000,  Valid loss  0.057,  Valid acc  0.983\n",
      "Epoch 9 : Train Loss  0.018, Train acc  1.000,  Valid loss  0.055,  Valid acc  0.984\n",
      "Epoch 10 : Train Loss  0.021, Train acc  0.990,  Valid loss  0.054,  Valid acc  0.985\n",
      "Test Loss  0.048, Test acc  0.984\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "batch_size = 100\n",
    "max_epochs = 10\n",
    "\n",
    "valid_loss, valid_accuracy = [], []\n",
    "train_loss, train_accuracy = [], []\n",
    "test_loss, test_accuracy = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Begin training loop')\n",
    "\n",
    "    try:\n",
    "        while mnist_data.train.epochs_completed < max_epochs:\n",
    "            _train_loss, _train_accuracy = [], []\n",
    "            \n",
    "            ## Run train op\n",
    "            x_batch, y_batch = mnist_data.train.next_batch(batch_size)\n",
    "            fetches_train = [train_op, cross_entropy, accuracy]\n",
    "            feed_dict_train = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _, _loss, _acc = sess.run(fetches_train, feed_dict_train)\n",
    "            \n",
    "            _train_loss.append(_loss)\n",
    "            _train_accuracy.append(_acc)\n",
    "            \n",
    "\n",
    "            ## Compute validation loss and accuracy\n",
    "            if mnist_data.train.epochs_completed % 1 == 0 \\\n",
    "                    and mnist_data.train._index_in_epoch <= batch_size:\n",
    "                train_loss.append(np.mean(_train_loss))\n",
    "                train_accuracy.append(np.mean(_train_accuracy))\n",
    "\n",
    "                fetches_valid = [cross_entropy, accuracy]\n",
    "                \n",
    "                feed_dict_valid = {x_pl: mnist_data.validation.images, y_pl: mnist_data.validation.labels}\n",
    "                _loss, _acc = sess.run(fetches_valid, feed_dict_valid)\n",
    "                \n",
    "                valid_loss.append(_loss)\n",
    "                valid_accuracy.append(_acc)\n",
    "                print(\"Epoch {} : Train Loss {:6.3f}, Train acc {:6.3f},  Valid loss {:6.3f},  Valid acc {:6.3f}\".format(\n",
    "                    mnist_data.train.epochs_completed, train_loss[-1], train_accuracy[-1], valid_loss[-1], valid_accuracy[-1]))\n",
    "        \n",
    "        \n",
    "        test_epoch = mnist_data.test.epochs_completed\n",
    "        while mnist_data.test.epochs_completed == test_epoch:\n",
    "            x_batch, y_batch = mnist_data.test.next_batch(batch_size)\n",
    "            feed_dict_test = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _loss, _acc = sess.run(fetches_valid, feed_dict_test)\n",
    "            test_loss.append(_loss)\n",
    "            test_accuracy.append(_acc)\n",
    "        print('Test Loss {:6.3f}, Test acc {:6.3f}'.format(\n",
    "                    np.mean(test_loss), np.mean(test_accuracy)))\n",
    "        \n",
    "        saver.save(sess, './mnist_cnn')\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We can then plot the validation and trianing accuracy over time.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.text.Text at 0x1cd688f9be0>,\n",
       " <matplotlib.text.Text at 0x1cd682e59e8>,\n",
       " (0.75, 1.03))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt4VdWd//H3lxAIEC5y0SoRQX9YRW6mKUqxCoot1o7o\n6DxCa23pTKkdteOldejlUWvrFH2c1lpbq7VobS3UwZHaPipTC9Z6Q0BFuWgFihouCkEgh1tI8v39\nsc4tIXBCyD47J/m8nuc855x99t5nnaD7s9dae61t7o6IiMjBdIq7ACIi0vYpLEREJCeFhYiI5KSw\nEBGRnBQWIiKSk8JCRERyUliIiEhOCgsREclJYSEiIjl1jrsAraV///4+ePDguIshIlJQli5dusXd\nB+Rar92ExeDBg1myZEncxRARKShm9k5z1lMzlIiI5KSwEBGRnBQWIiKSk8JCRERyUliIiEhOCgsR\nEclJYSEiIjkpLEREJCeFhYiI5KSwEBGRnBQWIiKSk8JCRERyUliIiEhOCgsREclJYSEiIjkpLERE\nJCeFhYiI5KSwEBGRnCILCzObZWYfmNnyA3xuZnaXma02s9fNrDzrsy+a2dvJxxejKqOIiDRPlDWL\nB4FJB/n8PGBo8jEduAfAzPoCNwGnAWOAm8zsiAjLKSIiOXSOasfu/qyZDT7IKpOBh9zdgZfMrI+Z\nHQ2MB/7s7lsBzOzPhNCZHVVZRaSV7dgBu3bFXYr8KiqC/v3BLO6SRCKysGiGgcB7We8rk8sOtFxE\n2qrt2+Fvf4MFC2DhQli2DNzjLlX+DRwIZ58NEyaEx+DBcZeo1cQZFk3Frx9k+f47MJtOaMJi0KBB\nrVcyETm4nTvhuecy4bB0KdTXQ9eu8IlPwM03w5FHxl3K/NqzB158EZ56Cn7zm7BsyJBMcEyYEMKk\nQMUZFpXAsVnvy4ANyeXjGy1/pqkduPt9wH0AFRUVHfA0RiRPdu8OB8KFC0NAvPwy1NZCcTGcdhp8\n5zvhjPr006GkJO7Sxueaa0KNasWKzN/qscdg1qzw+YknhtA4+2wYP76gAtU8wqpiss/iT+4+vInP\nzgeuAj5D6My+y93HJDu4lwKpq6NeAT6W6sM4kIqKCl+yZEkrll6kA6upgUWLwgFv4cIQFHv3hnb5\niorMmfK4cdCjR9ylbdvq6uD11zO1sGefherq8Nkpp2Sarc46C/r2zXvxzGypu1fkXC+qsDCz2YQa\nQn/gfcIVTsUA7v4LMzPgbkLn9S5gmrsvSW77ZeDbyV3d6u4P5Po+hYXIYaitDU1JqQPa88+HDmoz\nGD06c0D75CehV6+4S1vYamvhlVcyf+vnnsv8rUeNyvytzzwzL3/r2MMi3xQWIoegri50QqeaSv72\nt8zZ7vDhDQ9YMZztdig1NaFZL1WLe+GFUIvr1KlhLe6MMyKpxSksRCSjvr5hO/pf/wrbtoXPPvrR\nTDv6WWcVVDt6u5TqKE/VPBYtyvQPjRmTCfKxY1ulf0hhIW3TihWwalU8311SEjpjBwyI5/vzyR3e\neitztrpwIWzZEj47/viGV+gcc0y8ZZWDSyRCs2Dq33HJksyVZ2PHhvA455xwFVoLKCykbVmxAm66\nCR59NO6SwIgRmQPlWWfBEe1gggB3+Mc/MmejCxfCxo3hs7Kyhtf+H3dcvGWVw5Ma05KqJS5bBh//\neKiBtIDCQtqGt96C730P5syB0lK49lq4+OLQHptv27eHK1FSnYq7d4dOxVNPzRxIC6kD9733MgeM\nhQvh3XfD8qOOyjQrTZgAJ5zQbkcVC7B1K2zaBMOGtWhzhYXEa80auOUW+O1voVs3+PrX4frroV+/\nuEsW7N2b6VRcsCC0EdfUNLw09Oyzw6Wh3bvHXdpg06ZMrWHBgvA3hvA3HT8+U+aTTlI4SLMpLCQe\n77wD3/8+PPhg6JC78kq44Ya232maGnSWOktvPOgsdZaez0FnW7bAM89kAiLV19O7d2g+S9WGRoyI\np6Ymrco9XKRWUwP79jV8NF7W+H3PnuG8piUUFpJflZVw663wq1+Fs9orroAZM+Doo+MuWcskEqGp\nKnWgTk1nUVISOhJTB+qPfxy6dGmd79y2LVyllPrO118Py3v0CJewpr7z1FNDDUhaxD0cYPfsyTz2\n7m34vqWf5Tqo5wqCljrtNHjppZZtq7CQ/Ni4EWbOhHvvDQfTf/s3+Pa3Q6dqe5Ld37FwIbz2Wlje\no0e4/j11IC8vh87NnEWnurrh/EqvvpoJpHHjMrWZiopQw5H97N0Lq1eHStebb4bnDRtyH9wP97DX\nqVP4Z8p+dO0azhuKizOPXO+bs05ztundu8VdFgoLidjmzXDbbfDzn4dToy99Cb773XY1y+ZBVVVl\nagELFsDKlWF5r16ZWsDZZ8PIkZkmol27woCr1DaLF4d2hy5dQvNWKhxOOy0ceSRt27ZMGGQ/r10b\n/oQpxx0HgwaFbrLGB/PUAb01ljf3fKAQKCwkGlVVcMcd8NOfhnb+yy6DG28MV9x0ZO+/H/oXUrWE\nt98Oy/v2DeGxdWtoJ0h1oo8ZkwmUsWNbpRO9ri58zQcfhMf774fJYfv1C0NLUo8+fdpm/7d7aM1s\nKhQ2bcqs16VLmI/vpJPg5JMzzyeeqGmqWkJhIa1r2zb40Y/gzjtDe/6UKWHcxEc/GnfJ2qbKykyT\n1bPPhiN0quZwxhmhR7IZdu0KB/1UAKRCIPt9atmWLaEVK5fOncM9evr3bxgiB3r07du6Z9I1NaHp\nqKlQ2Lkzs16fPg3DIPU8eHD7OrOPm8JCWseOHXDXXfDf/x0C4+KLw70Khu83kbA0Q11dqJwd7KCf\n/T774JmtZ89wgdlRR4Xn7Ef2sh49wvdt3nzwx5Yt8OGHTX+XWRi3eLBAaRw8XbuGbp4339w/FNas\nadh0dOyxTYfCkUe2zRpQe9PcsFA+S9N27oS774bbbw9tGxdcEAbXjR4dd8kKwq5d4erbF14IV+Su\nW5c5+2/q/KyoqOEBf+jQA4fAgAGhTb65mjtge9++5gXL3/8eZp84WE2me/eGd1UtLg6/acQI+Jd/\nyYTCRz8axmpK26ewkIZ274Z77glXOG3eDOedFwbXVeQ88ejQNmwIwfD88+Hx6qthmAZkDozjxh24\nJtCnT/xDJYqL4SMfCY/mqK8PtZGmAqWqKuwn9duPP15NR4VO/3wS7N0Lv/wl/Nd/hcthJ04MITF2\nbNwla3Pq6sJUV6lgeP75UHOAcKXMmDHwzW+GcBg7tv3O8N2pU+g879cvBIK0bwqLjq6mBh54AH7w\ng9Ape+aZYR6nM8+M5KsefTSchR93XHgMHhzau9ty23QiEeZoSwXDSy+FrhwIZ8/jxoXZTMaNC610\nrTVGT6QtUVh0VLW18NBDYWqOdevCKfCDD4Yrdlr5yP3hh2HM3k9/GoKise7dM+GRCpDs5498JL9N\nNO+917DWsGxZaHIxC/36n/tcCIZx40IZ23LQibQWhUVH9NJLcPnlYSxARUXoo/j0p1v9qLd2bbjS\ndtas0F8+cWKYDWTMmDBB6jvvhJx6553M68WLQ3t3ti5dwkCrA4XJwIEtbw+vrQ2zamSHQ2Vl+KxH\njzA+7jvfCcFw+ulhpKxIR6Sw6Ejcw+n99deH6xX/8Af4p39q9ZB48cVwpe1jj4WrfKZOheuuC7cX\nTunb98AXViUSDQMk+/UTTzQcoAXhO8rKGgZI9utjj80MiN6+PWTl88+HDumXXspcnlpWlqkxjBsX\nBl+rU1Yk0P8KHcWOHWHepv/5H5g8OTQ59enTaruvq4N580JIvPhi2PUNN8DVVx/6jdhKS+GUU8Kj\nKXv2ZGom2YGybl0YA7d+fcNLOs3CfIa9eoXba7iHZq3Ro2HatEw4HHtsS3+9SPunsOgI3ngDLrkk\njIa6/Xb4xjdarTaRSIT+8TvvDM1Oxx8fxvBNmxbd9fMlJWFqhxNPbPrzfftCU1LjMPnww1DLGTcu\nNC/p+n6R5lNYtHe//jV87WvhVH/hwnAnuFawYUNo0br33nAQHjs25NCFF8Y/e3ZxMQwZEh4i0joU\nFu3Vnj2hDej++8N8RL/7XfNHWx3EsmVhiqjZs0PT00UXhS4QDccQad8UFu3RmjWh2em118K9Jb73\nvcPqqXWH+fNDf8TTT4erhK64Aq65JjQ7iUj7p7Bob+bNC/eW6NQJ/vQnOP/8Fu9q7154+OFQk1ix\nInRUz5wJ06eHieVEpONQWLQX+/aFWsQdd4RbfT7ySItvRLRlC/ziF2EewfffD5e8PvQQXHqpRieL\ndFQKi/Zgw4ZwJH/uObjyytBe1II7rf397/DjH4c+8d27wxyC118fyaBuESkwCotCt2BBuB50587Q\nZvS5zx3S5u7wt7+FfPnjH8OVRF/4QhhE19J7+opI+xPzpMjSYvX1cOutcO65YdrPxYsPKShqa8N8\ngWPGwFlnhRHN3/1uGOx2//0KChFpSDWLQlRVFU7/n3wyBMS99x50hFldXbhAavnyMD5v+fIwynr9\n+jCw7Z57wlRRrXAbaBFppyINCzObBPwEKALud/eZjT4/DpgFDAC2Ape5e2XyszrgjeSq77r7BVGW\ntWC8/HK41dimTeEo/9WvpjsU3EMALF/eMBhWrgzDLiCsesIJYVK8yy+Hz342/pvuiEjbF1lYmFkR\n8DPgXKASWGxmj7v7yqzV7gAecvdfm9nZwA+BLyQ/2+3uuodnijv8/Odw7bVwzDF8+ORLLC8+lTfu\naRgM27ZlNjnmmDCl9pVXhucRI8Kdy1SDEJFDFWXNYgyw2t3XApjZHGAykB0Ww4Brk68XAvMiLE9B\n2r0bVi7eyfIbHuKNRbtZPuBF3th7KhvOyVQHevcOQTBlSngePjxMwtevX4wFF5F2JcqwGAi8l/W+\nEjit0TrLgIsJTVUXAT3NrJ+7VwElZrYEqAVmuvt+QWJm04HpAIMGDWr9X5BHtbWwenWmhpB6Xr3a\nce8BfI2unWsZVlbExBHG8OGZ2sLAgbq0VUSiFWVYNHX48kbvvwHcbWZfAp4F1hPCAWCQu28ws+OB\nBWb2hruvabAz9/uA+wAqKioa77vNW7QoDHxbvhxWrQojpiH0IQwdCiP7vMPnin7LiB5rGX7XdE74\n3Gm6v4KIxCLKQ08lkH2HgDKgwU013X0D8M8AZlYKXOzu27M+w93XmtkzwKlAg7AodD/6Ubj/0IQJ\n4QrYVE3hpMF76Pata8JVTql7Yh99dNzFFZEOLMqwWAwMNbMhhBrDFKDBQAAz6w9sdfd64FuEK6Mw\nsyOAXe6+N7nOOOD2CMsai+rqcDe2J5/MWviPf8DES+CVV+A//xN+8APdrk1EYhfZUcjda83sKmA+\n4dLZWe6+wsxuAZa4++PAeOCHZuaEZqgrk5ufDNxrZvWEgYMzG11F1S4kEo2GR/zxj+F6VghVjgt0\ntbCItA2RnrK6+xPAE42W3Zj1ei4wt4ntXgBGRFm2tiCRCPd9prY2DJ++7TYoLw+3PtXc3yLShqh9\nI0aJBJQW7YZzJsGzz4YBdnfeGe4bKiLShigsYpT4sIbS+XPBloQ5wL/whdwbiYjEQGERo8S2WkqL\nqmHJonAplIhIG6VZgWLiDonaEkqPKFZQiEibp7CIye7d4HSitKQ298oiIjFTWMSkujo8l3avi7cg\nIiLNoLCISSIRnku7F9wsJSLSASksYpIKi56lCgsRafsUFjFJ1ywOfIM7EZE2Q2ERk3RY9NI/gYi0\nfTpSxSSxI3Rsl/YuirkkIiK5KSxikqiqAaC0j8ZFikjbp7CISWKrwkJECofCIiaJD/cBUNq3S8wl\nERHJTWERk+ptdXSijpI+mmFWRNo+hUVMEtvrKCWB9dS1syLS9iksYpKodkpJQI8ecRdFRCQn9a7G\nJJFwStmpsBCRgqCaRUwSCaMn1QoLESkICouYJHaamqFEpGAoLGKS2N1JYSEiBUNhEZPEns4KCxEp\nGAqLmCT2FFPaaRcUF8ddFBGRnBQWMUnUFFNaXBN3MUREmkVhEQN3qN5XQmkXhYWIFAaFRQz27IF6\n70Rp131xF0VEpFkUFjFI3/iopDbegoiINJPCIgbpsOheF29BRESaSWERg1RY9OxeH29BRESaSWER\ng3TNQhPOikiBiDQszGySmb1lZqvNbEYTnx9nZn8xs9fN7BkzK8v67Itm9nby8cUoy5lv6bDoGW85\nRESaK7KwMLMi4GfAecAwYKqZDWu02h3AQ+4+ErgF+GFy277ATcBpwBjgJjM7Iqqy5lsmLFSxE5HC\nEOXRagyw2t3XunsNMAeY3GidYcBfkq8XZn3+aeDP7r7V3T8E/gxMirCseZUOi14KCxEpDFEerQYC\n72W9r0wuy7YMuDj5+iKgp5n1a+a2mNl0M1tiZks2b97cagWPWmJH6Ngu7aPbiYhIYcgZFmY2xMxK\nst53M7PBzdi3NbHMG73/BnCWmb0KnAWsB2qbuS3ufp+7V7h7xYABA5pRpLahuiqM3C49QvNCiUhh\naE7N4n+A7Gs865LLcqkEjs16XwZsyF7B3Te4+z+7+6nAd5LLtjdn20KW+HAfRj3d+nSNuygiIs3S\nnLDonOxzACD5uksztlsMDE3WTLoAU4DHs1cws/5mlirDt4BZydfzgU+Z2RHJju1PJZe1C4ntdfRg\nJ516anpyESkMzQmLzWZ2QeqNmU0GtuTayN1rgasIB/lVwCPuvsLMbsna33jgLTP7O3AUcGty263A\n9wmBsxi4JbmsXUhsr9O9LESkoDSnh/UK4GEzuzv5vhK4vDk7d/cngCcaLbsx6/VcYO4Btp1FpqbR\nriR21Ov+2yJSUHKGhbuvAU43s1LA3L06+mK1b4mEq2YhIgWlOVdD/ZeZ9XH3hLtXJ/sRfpCPwrVX\niYQpLESkoDSnz+I8d9+WepMcJPeZ6IrU/iV2KSxEpLA0JyyKzCx9jaeZdQN0zedhSOwqCmGhmQRF\npEA0p4P7t8BfzOyB5PtpwK+jK1L7V727s2oWIlJQmtPBfbuZvQ5MJIysfgo4LuqCtWeJvQoLESks\nzZ0bahNhFPfFwDmEcRPSAu6QqOlCaafd0FlzQ4lIYTjg0crMTiSMup4KVAG/J1w6OyFPZWuXamqg\ntr6I0pKa3CuLiLQRBzu1fRP4G/BP7r4awMyuzUup2rH09ORd98VbEBGRQ3CwZqiLCc1PC83sl2Z2\nDk3PBiuHIH3/7W618RZEROQQHDAs3P0xd78UOAl4BrgWOMrM7jGzT+WpfO1OumbRvS7egoiIHIKc\nHdzuvtPdH3b3zxKmCn8N2O9+2tI8mbDY7/YcIiJt1iHdKS95m9N73f3sqArU3qXDoofCQkQKh24C\nnWfpsNDgbREpIAqLPKtOztlb2kt/ehEpHDpi5Vm6ZqGwEJECoiNWnqXDoo9Gb4tI4VBY5FliRz0A\n3fs05zbmIiJtg05v8yzx4T66U0tRz+5xF0VEpNlUs8izxLZazTgrIgVHYZFniR119KRaYSEiBUVh\nkWeJHa6ahYgUHIVFniWqFRYiUngUFnmW2Inuvy0iBUdhkWfVOzupZiEiBUdhkWeJXQoLESk8Cos8\nS+zprLAQkYKjsMgzhYWIFCKFRR7V1EBNncJCRApPpGFhZpPM7C0zW21m+91dz8wGmdlCM3vVzF43\ns88klw82s91m9lry8Ysoy5kvO3eG59KiPdBZM62ISOGI7IhlZkXAz4BzgUpgsZk97u4rs1b7LvCI\nu99jZsOAJ4DByc/WuPvoqMoXh9SMsz1LauItiIjIIYqyZjEGWO3ua929BpgDTG60jgO9kq97Axsi\nLE/s0tOTl9TFWxARkUMUZVgMBN7Lel+ZXJbtZuAyM6sk1CquzvpsSLJ56q9m9skIy5k36bDoprAQ\nkcISZVhYE8u80fupwIPuXgZ8BviNmXUCNgKD3P1U4Drgd2bWq9G2mNl0M1tiZks2b97cysVvfelb\nqnavj7cgIiKHKMqwqASOzXpfxv7NTP8KPALg7i8CJUB/d9/r7lXJ5UuBNcCJjb/A3e9z9wp3rxgw\nYEAEP6F1pWsWPRpnpohI2xZlWCwGhprZEDPrAkwBHm+0zrvAOQBmdjIhLDab2YBkBzlmdjwwFFgb\nYVnzIh0WmhZKRApMZFdDuXutmV0FzAeKgFnuvsLMbgGWuPvjwPXAL83sWkIT1Zfc3c3sTOAWM6sF\n6oAr3H1rVGXNl3RY9NLwFhEpLJFe7O/uTxA6rrOX3Zj1eiUwrontHgUejbJscUiHRe+ieAsiInKI\ndIqbR6mw6NFbA/JEpLAoLPIokYASdtO5Z7e4iyIickgUFnmU2FGv+2+LSEFSWORRYlutJhEUkYKk\nsMijxI46hYWIFCSFRR5Vb3fdf1tECpLCIo8S1a6ahYgUJIVFHiV2orAQkYKksMijxE5TWIhIQVJY\n5FFid5HCQkQKksIijxQWIlKoFBZ5UlsLe/Z1VliISEFSWOTJzp3huSfVunRWRAqOwiJP0jPOqmYh\nIgVIYZEn6bDovBeKNEW5iBQWhUWepO+/XVIbb0FERFpAYZEn6ZpFt7p4CyIi0gIKizxJh0X3+ngL\nIiLSAgqLPEmHRQ+PtyAiIi2gsMiTdFj0tHgLIiLSAgqLPEmHRS/9yUWk8OjIlScKCxEpZDpy5Uki\nAV3ZQ3HPkriLIiJyyBQWeZJIQKnt1OhtESlICos8qa6GUq9WWIhIQVJY5Emiul7zQolIwVJY5Eli\ne10IC804KyIFSGGRJ4kdqlmISOFSWORJolrTk4tI4VJY5Elip8JCRApXpGFhZpPM7C0zW21mM5r4\nfJCZLTSzV83sdTP7TNZn30pu95aZfTrKcuZDYqcpLESkYHWOasdmVgT8DDgXqAQWm9nj7r4ya7Xv\nAo+4+z1mNgx4AhicfD0FOAU4BnjazE5094Kd3zuxq5PCQkQKVpQ1izHAandf6+41wBxgcqN1HOiV\nfN0b2JB8PRmY4+573f0fwOrk/gpSXR3s2ttZV0OJSMGKMiwGAu9lva9MLst2M3CZmVUSahVXH8K2\nBWPXrvDcEw3KE5HCFGVYNDUXd+ObOUwFHnT3MuAzwG/MrFMzt8XMppvZEjNbsnnz5sMucFTSt1RV\nM5SIFKjI+iwItYFjs96XkWlmSvlXYBKAu79oZiVA/2Zui7vfB9wHUFFR0WbvKpSecVZhIdIi+/bt\no7Kykj179sRdlIJVUlJCWVkZxcXFLdo+yrBYDAw1syHAekKH9ecarfMucA7woJmdDJQAm4HHgd+Z\n2Y8IHdxDgZcjLGukFBYih6eyspKePXsyePBgzHQDsUPl7lRVVVFZWcmQIUNatI/ImqHcvRa4CpgP\nrCJc9bTCzG4xswuSq10PfMXMlgGzgS95sAJ4BFgJPAVcWdBXQqXCorgGioriLYxIAdqzZw/9+vVT\nULSQmdGvX7/DqplFWbPA3Z8gdFxnL7sx6/VKYNwBtr0VuDXK8uVLOiy6FWzeicROQXF4DvfvpxHc\neZAOi+718RZERFqkqqqK0aNHM3r0aD7ykY8wcODA9Puamppm7WPatGm89dZbh/zd559/Pp/85CcP\nebvWFmnNQoJ0WGiIhUhB6tevH6+99hoAN998M6WlpXzjG99osI674+506tT0OfgDDzxwyN9bVVXF\nG2+8QUlJCe+++y6DBg069MK3EtUs8kBhIdI+rV69muHDh3PFFVdQXl7Oxo0bmT59OhUVFZxyyinc\ncsst6XXPOOMMXnvtNWpra+nTpw8zZsxg1KhRjB07lg8++KDJ/c+dO5cLL7yQSy+9lN///vfp5Zs2\nbWLy5MmMHDmSUaNGsWjRIiAEUmrZtGnTWvW3qmaRB+mw6Kk2V5HDds01kDzLbzWjR8Odd7Zo05Ur\nV/LAAw/wi1/8AoCZM2fSt29famtrmTBhApdccgnDhg1rsM327ds566yzmDlzJtdddx2zZs1ixoz9\nps9j9uzZ/PCHP6R3795cdtllfPOb3wTgyiuv5Nxzz+Wqq66itraWXbt2sWzZMm677TZeeOEF+vbt\ny9atW1v0ew5ENYs8SCSg2PbRtWeXuIsiIq3shBNO4OMf/3j6/ezZsykvL6e8vJxVq1axcuXK/bbp\n1q0b5513HgAf+9jHWLdu3X7rrF+/nnfffZfTTz+dYcOGUVdXx5tvvgnAM888w1e/+lUAOnfuTK9e\nvViwYAGXXnopffv2BUg/txbVLPKguhpKbafGWIi0hhbWAKLSI+v/67fffpuf/OQnvPzyy/Tp04fL\nLrusyctVu3TJnDgWFRVRW1u73zq///3vqaqqSo+L2L59O3PmzOHmm28G9r+6yd0jvWJMNYs8SCQU\nFiIdwY4dO+jZsye9evVi48aNzJ8/v8X7mj17Nk8//TTr1q1j3bp1vPzyy8yePRuACRMmpJu96urq\n2LFjBxMnTmTOnDnp5ic1QxWgRAJKXTPOirR35eXlDBs2jOHDh/OVr3yFceOaHEaW05o1a9i0aRMV\nFRXpZUOHDqVr164sXbqUu+++m/nz5zNixAgqKip48803GTlyJDfccANnnnkmo0ePTvdvtBZzb7NT\nKh2SiooKX7JkSdzFaNJ550HV/MW8fMOjMHNm3MURKTirVq3i5JNPjrsYBa+pv6OZLXX3igNskqaa\nRR4kquspdU1PLiKFS2GRB4kd9ZpEUEQKmsIiDxLVmnFWRAqbwiIPEjsVFiJS2BQWeZDYabr/togU\nNIVFxOrrIbGrSPffFpGCprCI2K5d4VnNUCKFa/z48fsNsLvzzjv593//94NuV3qQ1oTHHnsMM0tP\n4dHWKSwipluqihS+qVOnMmfOnAbL5syZw9SpU1u8z9mzZ3PGGWfst9+2SmERMYWFSOG75JJL+NOf\n/sTevXsBWLduHRs2bOCMM84gkUhwzjnnUF5ezogRI/jDH/6Qc3+JRILnn3+eX/3qV/uFxe23386I\nESMYNWpUeiba1atXM3HiREaNGkV5eTlr1qxp/R+ZgyYSjJjCQqR1xTFDeb9+/RgzZgxPPfUUkydP\nZs6cOVx66aWYGSUlJTz22GP06tWLLVu2cPrpp3PBBRccdFK/efPmMWnSJE488UT69u3LK6+8Qnl5\nOU8++SREaUfRAAAItUlEQVTz5s1j0aJFdO/ePT2/0+c//3lmzJjBRRddxJ49e6ivz/9dN1WziJjC\nQqR9yG6Kym6Ccne+/e1vM3LkSCZOnMj69et5//33D7qv2bNnM2XKFACmTJmSniDw6aefZtq0aXTv\n3h0I04xXV1ezfv16LrroIgBKSkrSn+eTahYRU1iItK64Zii/8MILue6663jllVfYvXs35eXlADz8\n8MNs3ryZpUuXUlxczODBg5ucljylqqqKBQsWsHz5csyMuro6zIzbb7+9yWnG28r8fapZRCwdFl32\nQVFRvIURkRYrLS1l/PjxfPnLX27Qsb19+3aOPPJIiouLWbhwIe+8885B9zN37lwuv/xy3nnnHdat\nW8d7773HkCFDeO655/jUpz7FrFmz2JW8jHLr1q306tWLsrIy5s2bB8DevXvTn+eTwiJi6bDonv82\nRhFpXVOnTmXZsmXpJiQI/QlLliyhoqKChx9+mJNOOumg+5g9e3a6SSnl4osv5ne/+x2TJk3iggsu\noKKigtGjR3PHHXcA8Jvf/Ia77rqLkSNH8olPfIJNmza1/o/LQVOUR+zuu+Hqq+GDgacyoPLVuIsj\nUpA0RXnr0BTlbVh1dXjuWdo+QllEOiaFRcQSCSiyOrqWFsddFBGRFlNYRCyRgNJOu7BSXQklIoVL\nYRGxVFhoxlmRw9Ne+lfjcrh/P4VFxBIJKGWnxliIHIaSkhKqqqoUGC3k7lRVVVFSUtLifWhQXsRC\nWGh6cpHDUVZWRmVlJZs3b467KAWrpKSEsrKyFm8faViY2STgJ0ARcL+7z2z0+Y+BCcm33YEj3b1P\n8rM64I3kZ++6+wVRljUqiQSU1issRA5HcXExQ4YMibsYHVpkYWFmRcDPgHOBSmCxmT3u7itT67j7\ntVnrXw2cmrWL3e4+Oqry5UsiAUfXb1dYiEhBi7LPYgyw2t3XunsNMAeYfJD1pwKzIyxPLBLVTqmr\nZiEihS3KsBgIvJf1vjK5bD9mdhwwBFiQtbjEzJaY2UtmdmF0xYxWIuGaRFBECl6UfRZNTeZ+oEsZ\npgBz3b0ua9kgd99gZscDC8zsDXdvcMcPM5sOTE++TZjZW4dR3v7AlsPY/oB+BfzqeuD666PY/eGI\n7De3UR3t94J+c0dxOL/5uOasFGVYVALHZr0vAzYcYN0pwJXZC9x9Q/J5rZk9Q+jPWNNonfuA+1qj\nsGa2pDnzo7QnHe03d7TfC/rNHUU+fnOUzVCLgaFmNsTMuhAC4fHGK5nZR4EjgBezlh1hZl2Tr/sD\n44CVjbcVEZH8iKxm4e61ZnYVMJ9w6ewsd19hZrcAS9w9FRxTgTnecLTNycC9ZlZPCLSZ2VdRiYhI\nfkU6zsLdnwCeaLTsxkbvb25iuxeAEVGWrQmt0pxVYDrab+5ovxf0mzuKyH9zu7mfhYiIREdzQ4mI\nSE4dPizMbJKZvWVmq81sRtzliZqZHWtmC81slZmtMLP/iLtM+WJmRWb2qpn9Ke6y5IOZ9TGzuWb2\nZvLfe2zcZYqamV2b/O96uZnNNrOWz5zXRpnZLDP7wMyWZy3ra2Z/NrO3k89HtPb3duiwyJqS5Dxg\nGDDVzIbFW6rI1QLXu/vJwOnAlR3gN6f8B7Aq7kLk0U+Ap9z9JGAU7fy3m9lA4OtAhbsPJ1xYM+Xg\nWxWkB4FJjZbNAP7i7kOBvyTft6oOHRYc+pQkBc/dN7r7K8nX1YQDSJMj69sTMysDzgfuj7ss+WBm\nvYAzCWNCcfcad98Wb6nyojPQzcw6EyYnPdDYroLl7s8CWxstngz8Ovn610Crz3rR0cOi2VOStEdm\nNpgw2HFRvCXJizuBG4D6uAuSJ8cDm4EHkk1v95tZu55zxt3XA3cA7wIbge3u/n/xlipvjnL3jRBO\nCIEjW/sLOnpYHMqUJO2KmZUCjwLXuPuOuMsTJTP7LPCBuy+Nuyx51BkoB+5x91OBnUTQNNGWJNvp\nJxPmmTsG6GFml8Vbqvajo4fFoUxJ0m6YWTEhKB529/+Nuzx5MA64wMzWEZoazzaz38ZbpMhVApXu\nnqo1ziWER3s2EfiHu292933A/wKfiLlM+fK+mR0NkHz+oLW/oKOHRbOmJGlPzMwI7dir3P1HcZcn\nH9z9W+5e5u6DCf/GC9y9XZ9xuvsm4L3kdDoA59D+p8x5FzjdzLon/zs/h3beqZ/lceCLyddfBP7Q\n2l/QoW+reqApSWIuVtTGAV8A3jCz15LLvp0cbS/ty9XAw8kTobXAtJjLEyl3X2Rmc4FXCFf9vUo7\nHM1tZrOB8UB/M6sEbgJmAo+Y2b8SQvNfWv17NYJbRERy6ejNUCIi0gwKCxERyUlhISIiOSksREQk\nJ4WFiIjkpLAQycHM6szstaxHq42ENrPB2bOHirRVHXqchUgz7Xb30XEXQiROqlmItJCZrTOz28zs\n5eTj/yWXH2dmfzGz15PPg5LLjzKzx8xsWfKRmoqiyMx+mbwPw/+ZWbfk+l83s5XJ/cyJ6WeKAAoL\nkebo1qgZ6tKsz3a4+xjgbsLMtiRfP+TuI4GHgbuSy+8C/uruowjzNKVmCxgK/MzdTwG2ARcnl88A\nTk3u54qofpxIc2gEt0gOZpZw99Imlq8Dznb3tcnJGTe5ez8z2wIc7e77kss3unt/M9sMlLn73qx9\nDAb+nLxpDWb2n0Cxu//AzJ4CEsA8YJ67JyL+qSIHpJqFyOHxA7w+0DpN2Zv1uo5MX+L5hDs5fgxY\nmryhj0gsFBYih+fSrOcXk69fIHM7z88DzyVf/wX4GqTvB97rQDs1s07Ase6+kHDTpj7AfrUbkXzR\nmYpIbt2yZuiFcF/r1OWzXc1sEeHEa2py2deBWWb2TcLd6lKzvf4HcF9yZtA6QnBsPMB3FgG/NbPe\nhJt0/biD3BZV2ij1WYi0ULLPosLdt8RdFpGoqRlKRERyUs1CRERyUs1CRERyUliIiEhOCgsREclJ\nYSEiIjkpLEREJCeFhYiI5PT/AZOh7h4xloyKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cd681cd630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = np.arange(len(train_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_accuracy,'r', epoch, valid_accuracy,'b')\n",
    "plt.legend(['Train Acc','Val Acc'], loc=4)\n",
    "plt.xlabel('Epochs'), plt.ylabel('Acc'), plt.ylim([0.75,1.03])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We can then make predictions on the test set</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist_cnn\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:    \n",
    "    saver.restore(sess, './mnist_cnn')\n",
    "    feed_dict_valid = {x_pl: mnist_data.test.images, y_pl: mnist_data.test.labels}\n",
    "\n",
    "    # deciding which parts to fetch\n",
    "    fetches_valid = [accuracy]          \n",
    "\n",
    "    # running the validation\n",
    "    test_acc = sess.run(fetches=fetches_valid, feed_dict=feed_dict_valid)\n",
    "    \n",
    "    y_pred = pred(mnist_data.test.images, sess)    # Get predictions\n",
    "    \n",
    "    y_pred_1 = np.zeros_like(y_pred) # Make new matrix to contain one-hot encoded values of y_pred\n",
    "    y_pred_1[np.arange(len(y_pred)), y_pred.argmax(1)] = 1 # Sets max to 1 and everything else to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy using elu is [0.98420012]\n"
     ]
    }
   ],
   "source": [
    "print('The test accuracy using elu is {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> EXE 1.3 </span> Play around with the network.\n",
    "The MNIST dataset is so easy to solve with convolutional networks that it isn't interesting to spend to much time on maximizing performance.\n",
    "A more interesting question is *how few parameters can you solve it with?*\n",
    "\n",
    "1. Try and minimize the number of parameters, while keeping validation accuracy about 95%. Try changing the\n",
    "\n",
    "    * Number of layers\n",
    "    * Number of filters\n",
    "    * Kernel size\n",
    "    * Pooling size\n",
    "1. Once happy take note of the performance, number of parameters (printed automatically), and describe the network below.\n",
    "___\n",
    "\n",
    "\n",
    "<span style=\"color:blue\"> Answer: </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', \n",
    "                                       one_hot=True,   # Convert the labels into one hot encoding\n",
    "                                       dtype='float32', # rescale images to `[0, 1]`\n",
    "                                       reshape=False, # Don't flatten the images to vectors\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">I just remove one layer and reduce the number of filters.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace of the tensors shape as it is propagated through the network.\n",
      "Layer name \t Output size\n",
      "----------------------------\n",
      "x_pl \t\t (?, 28, 28, 1)\n",
      "conv1 \t\t (?, 28, 28, 10)\n",
      "pool1 \t\t (?, 14, 14, 10)\n",
      "conv2 \t\t (?, 14, 14, 14)\n",
      "pool2 \t\t (?, 1, 1, 14)\n",
      "Flatten \t (?, 14)\n",
      "denseOut\t (?, 10)\n",
      "Model consits of  1684 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "filters_1 = 10\n",
    "kernel_size_1 = (5,5)\n",
    "pool_size_1 = (2,2)\n",
    "\n",
    "filters_2 = 14\n",
    "kernel_size_2 = (3,3)\n",
    "pool_size_2 = (filters_2, filters_2)\n",
    "\n",
    "x_pl = tf.placeholder(tf.float32, [None, height, width, nchannels], name='xPlaceholder')\n",
    "y_pl = tf.placeholder(tf.float64, [None, num_classes], name='yPlaceholder')\n",
    "y_pl = tf.cast(y_pl, tf.float32)\n",
    "\n",
    "print('Trace of the tensors shape as it is propagated through the network.')\n",
    "print('Layer name \\t Output size')\n",
    "print('----------------------------')\n",
    "\n",
    "with tf.variable_scope('convLayer1'):\n",
    "    conv1 = Conv2D(filters_1, kernel_size_1, strides=(1,1), padding=padding, activation='relu')\n",
    "    print('x_pl \\t\\t', x_pl.get_shape())\n",
    "    x = conv1(x_pl)\n",
    "    print('conv1 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=pool_size_1, strides=None, padding=padding)\n",
    "    x = pool1(x)\n",
    "    print('pool1 \\t\\t', x.get_shape())\n",
    "    \n",
    "with tf.variable_scope('convLayer2'):\n",
    "    conv2 = Conv2D(filters_2, kernel_size_2, strides=(1,1), padding=padding, activation='relu')\n",
    "    x = conv2(x)\n",
    "    print('conv2 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=pool_size_2, strides=None, padding=padding)\n",
    "    x = pool2(x)\n",
    "    print('pool2 \\t\\t', x.get_shape())\n",
    "    \n",
    "    x = flatten(x)\n",
    "    print('Flatten \\t', x.get_shape()) \n",
    "    \n",
    "with tf.variable_scope('output_layer'):\n",
    "    denseOut = Dense(units=num_classes, activation='softmax')\n",
    "    \n",
    "    y = denseOut(x)\n",
    "    print('denseOut\\t', y.get_shape())    \n",
    "\n",
    "print('Model consits of ', utils.num_params(), 'trainable parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">So now, we only have 1684 parameters.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    # computing cross entropy per sample\n",
    "    cross_entropy = -tf.reduce_sum(y_pl * tf.log(y+1e-8), reduction_indices=[1])\n",
    "\n",
    "    # averaging over samples\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "with tf.variable_scope('training'):\n",
    "    # defining our optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "    # applying the gradients\n",
    "    train_op = optimizer.minimize(cross_entropy)\n",
    "\n",
    "with tf.variable_scope('performance'):\n",
    "    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n",
    "    correct_prediction = tf.equal(tf.argmax(y, axis=1), tf.argmax(y_pl, axis=1))\n",
    "\n",
    "    # averaging the one-hot encoded vector\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "# Add saver op to restore the model for prediction  \n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training loop\n",
      "Epoch 0 : Train Loss  2.379, Train acc  0.110,  Valid loss  2.354,  Valid acc  0.087\n",
      "Epoch 1 : Train Loss  0.626, Train acc  0.830,  Valid loss  0.582,  Valid acc  0.835\n",
      "Epoch 2 : Train Loss  0.433, Train acc  0.870,  Valid loss  0.364,  Valid acc  0.893\n",
      "Epoch 3 : Train Loss  0.289, Train acc  0.890,  Valid loss  0.302,  Valid acc  0.911\n",
      "Epoch 4 : Train Loss  0.198, Train acc  0.950,  Valid loss  0.249,  Valid acc  0.926\n",
      "Epoch 5 : Train Loss  0.231, Train acc  0.900,  Valid loss  0.233,  Valid acc  0.933\n",
      "Epoch 6 : Train Loss  0.096, Train acc  0.980,  Valid loss  0.213,  Valid acc  0.936\n",
      "Epoch 7 : Train Loss  0.286, Train acc  0.920,  Valid loss  0.199,  Valid acc  0.937\n",
      "Epoch 8 : Train Loss  0.118, Train acc  0.980,  Valid loss  0.192,  Valid acc  0.941\n",
      "Epoch 9 : Train Loss  0.168, Train acc  0.950,  Valid loss  0.187,  Valid acc  0.942\n",
      "Epoch 10 : Train Loss  0.200, Train acc  0.940,  Valid loss  0.176,  Valid acc  0.946\n",
      "Test Loss  0.173, Test acc  0.947\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "batch_size = 100\n",
    "max_epochs = 10\n",
    "\n",
    "valid_loss, valid_accuracy = [], []\n",
    "train_loss, train_accuracy = [], []\n",
    "test_loss, test_accuracy = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Begin training loop')\n",
    "\n",
    "    try:\n",
    "        while mnist_data.train.epochs_completed < max_epochs:\n",
    "            _train_loss, _train_accuracy = [], []\n",
    "            \n",
    "            ## Run train op\n",
    "            x_batch, y_batch = mnist_data.train.next_batch(batch_size)\n",
    "            fetches_train = [train_op, cross_entropy, accuracy]\n",
    "            feed_dict_train = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _, _loss, _acc = sess.run(fetches_train, feed_dict_train)\n",
    "            \n",
    "            _train_loss.append(_loss)\n",
    "            _train_accuracy.append(_acc)\n",
    "            \n",
    "\n",
    "            ## Compute validation loss and accuracy\n",
    "            if mnist_data.train.epochs_completed % 1 == 0 \\\n",
    "                    and mnist_data.train._index_in_epoch <= batch_size:\n",
    "                train_loss.append(np.mean(_train_loss))\n",
    "                train_accuracy.append(np.mean(_train_accuracy))\n",
    "\n",
    "                fetches_valid = [cross_entropy, accuracy]\n",
    "                \n",
    "                feed_dict_valid = {x_pl: mnist_data.validation.images, y_pl: mnist_data.validation.labels}\n",
    "                _loss, _acc = sess.run(fetches_valid, feed_dict_valid)\n",
    "                \n",
    "                valid_loss.append(_loss)\n",
    "                valid_accuracy.append(_acc)\n",
    "                print(\"Epoch {} : Train Loss {:6.3f}, Train acc {:6.3f},  Valid loss {:6.3f},  Valid acc {:6.3f}\".format(\n",
    "                    mnist_data.train.epochs_completed, train_loss[-1], train_accuracy[-1], valid_loss[-1], valid_accuracy[-1]))\n",
    "        \n",
    "        \n",
    "        test_epoch = mnist_data.test.epochs_completed\n",
    "        while mnist_data.test.epochs_completed == test_epoch:\n",
    "            x_batch, y_batch = mnist_data.test.next_batch(batch_size)\n",
    "            feed_dict_test = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _loss, _acc = sess.run(fetches_valid, feed_dict_test)\n",
    "            test_loss.append(_loss)\n",
    "            test_accuracy.append(_acc)\n",
    "        print('Test Loss {:6.3f}, Test acc {:6.3f}'.format(\n",
    "                    np.mean(test_loss), np.mean(test_accuracy)))\n",
    "        \n",
    "        saver.save(sess, './mnist_cnn')\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.text.Text at 0x2313c1e5908>,\n",
       " <matplotlib.text.Text at 0x231374c3d68>,\n",
       " (0.75, 1.03))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC+ecc2H9P/3cSOiILteKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23137321cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = np.arange(len(train_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_accuracy,'r', epoch, valid_accuracy,'b')\n",
    "plt.legend(['Train Acc','Val Acc'], loc=4)\n",
    "plt.xlabel('Epochs'), plt.ylabel('Acc'), plt.ylim([0.75,1.03])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We can then make predictions on the test set</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist_cnn\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:    \n",
    "    saver.restore(sess, './mnist_cnn')\n",
    "    feed_dict_valid = {x_pl: mnist_data.test.images, y_pl: mnist_data.test.labels}\n",
    "\n",
    "    # deciding which parts to fetch\n",
    "    fetches_valid = [accuracy]          \n",
    "\n",
    "    # running the validation\n",
    "    test_acc = sess.run(fetches=fetches_valid, feed_dict=feed_dict_valid)\n",
    "    \n",
    "    y_pred = pred(mnist_data.test.images, sess)    # Get predictions\n",
    "    \n",
    "    y_pred_1 = np.zeros_like(y_pred) # Make new matrix to contain one-hot encoded values of y_pred\n",
    "    y_pred_1[np.arange(len(y_pred)), y_pred.argmax(1)] = 1 # Sets max to 1 and everything else to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy using elu is [0.94680017]\n"
     ]
    }
   ],
   "source": [
    "print('The test accuracy using elu is {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> EXE 1.4 </span> Comparing dense and convolutional networks\n",
    "\n",
    "1. Now create a densely connected network (the ones from lab 1), and see how good performance you can get with a similar number of parameters.\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">If you run this notebook, you may be required to restart the kernel for this section, the first cells then need to be executed again for the variables and modules.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', \n",
    "                                       one_hot=True,   # Convert the labels into one hot encoding\n",
    "                                       dtype='float32', # rescale images to `[0, 1]`\n",
    "                                       reshape=True, # Flatten the images to vectors\n",
    "                                      )\n",
    "\n",
    "num_features = mnist_data.train.images[0].shape[0]\n",
    "num_classes = mnist_data.train.labels[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">As a vector, we have 784 features, this means that with just 2 neurons in the hidden layer, we will have 1568 weights.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "session = K.get_session()\n",
    "if model is not None:\n",
    "    model.reset_states() # Reset graph\n",
    "\n",
    "n_hidden1 = 2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(n_hidden1, activation='elu', input_dim=num_features))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2)                 1570      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                30        \n",
      "=================================================================\n",
      "Total params: 1,600\n",
      "Trainable params: 1,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Developer\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.469999987483\n",
      "0.532599983215\n",
      "0.559799978137\n",
      "0.566799976826\n",
      "0.580399978757\n",
      "0.593399971724\n",
      "0.59839998126\n",
      "0.599999974966\n",
      "0.606199983358\n",
      "0.611599975228\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "#history = model.fit(mnist_data.train.images, mnist_data.train.labels, batch_size=100, epochs=10)\n",
    "\n",
    "for e in range(epochs):\n",
    "    train_loss = model.fit(mnist_data.train.images, mnist_data.train.labels, batch_size=batch_size, nb_epoch=1, verbose = 0)\n",
    "    val_score, val_acc = model.evaluate(mnist_data.validation.images, mnist_data.validation.labels, batch_size=batch_size, verbose = 0)\n",
    "    \n",
    "    print(\"Validation accuracy: {}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We then obtain the test accuracy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.14701682673\n",
      "Test accuracy: 0.6006\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(mnist_data.test.images, mnist_data.test.labels, verbose=0)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">So it is significantly worse than the convolutional neural network.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Book Exercise](http://neuralnetworksanddeeplearning.com/chap3.html#exercise_35813)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I have provided the link to the exercise in the heading. \n",
    "In the following, I will not write the text in blue since this is only the book exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that $\\sigma ' (z) = \\sigma(z)(1-\\sigma(z))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sigma(z) = \\frac{1}{1+e^{-z}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differentiating gives us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\sigma(z)'&= \\frac{e^{-z}}{(1+e^{-z})^2} \\\\\n",
    "              &= \\frac{1+e^{-z}}{(1+e^{-z})^2} - \\frac{1}{(1+e^{-z})^2} \\\\\n",
    "              &= \\frac{1}{1+e^{-z}} - \\frac{1}{(1+e^{-z})^2} \\\\\n",
    "              &= \\sigma(z) - \\sigma(z)^2 \\\\\n",
    "              &= \\sigma(z) (1- \\sigma(z))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is what we wanted."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
