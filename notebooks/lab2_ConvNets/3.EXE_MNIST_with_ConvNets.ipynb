{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with ConvNets\n",
    "\n",
    "> <span style=\"color:gray\">\n",
    "Original [Theano/Lasagne tutorial](https://github.com/DeepLearningDTU/nvidia_deep_learning_summercamp_2016/blob/master/lab1/lab1_FFN.ipynb) by \n",
    "Lars Maaløe ([larsmaaloee](https://github.com/larsmaaloee)),\n",
    "Søren Kaae Sønderby ([skaae](https://github.com/skaae)), and \n",
    "Casper Sønderby ([casperkaae](https://github.com/casperkaae)). \n",
    "Converted to TensorFlow by \n",
    "Alexander R. Johansen ([alrojo](https://github.com/alrojo)), \n",
    "and updated by \n",
    "Toke Faurby ([faur](https://github.com/Faur)).\n",
    "</span>\n",
    "\n",
    "\n",
    "In this lab we will solve the MNIST problem again, but this time with convolutional networks.\n",
    "You will get a to try stacking of convolutional layers, max pooling and strided convolutions which are all important techniques in current convolutional layers network architectures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependancies and supporting functions\n",
    "\n",
    "\n",
    "Loading dependancies and supporting functions by running the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import sklearn.datasets\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join('.', '..')) \n",
    "import utils \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.contrib.layers import flatten # We use this flatten, as it works better than \n",
    "                                              # the Keras 'Flatten' for some reason\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred(X_in, sess):\n",
    "    # first we must define what data to give it\n",
    "    feed_dict = {x_pl: X_in}\n",
    "    # secondly our fetches\n",
    "    fetches = [y]\n",
    "    # utilizing the given session (ref. sess) to compute results\n",
    "    res = sess.run(fetches, feed_dict)\n",
    "    # res is a list with each indices representing the corresponding element in fetches\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST data set\n",
    "\n",
    "We load the MNIST dataset.\n",
    "This time the data is keept as images (`shape = [28, 28, 1]`), and not flattended into vectors (`shape = [784]`).\n",
    "This allows the convolutional network to take advantage of the structure of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Information on dataset\n",
      "    ----------------------\n",
      "Training size:\t 55000\n",
      "Test size\t 10000\n",
      "Validation size\t 5000\n",
      "\n",
      "Data summaries\n",
      "Image shape\t\t (28, 28, 1)\n",
      "Image type\t\t <class 'numpy.ndarray'>\n",
      "Image min/max value\t 0.0 / 1.0\n",
      "Label shape\t\t (10,)\n",
      "Label type\t\t <class 'numpy.float64'>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAEICAYAAABWCOFPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCgoKCiYoo6CgoGDC/wPG7l7oloY3bwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a5a21fcb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data (download if you haven't already)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', \n",
    "                                       one_hot=True,   # Convert the labels into one hot encoding\n",
    "                                       dtype='float32', # rescale images to `[0, 1]`\n",
    "                                       reshape=False, # Don't flatten the images to vectors\n",
    "                                      )\n",
    "## Print dataset statistics and visualize\n",
    "print('')\n",
    "utils.mnist_summary(mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.45)\n",
    "\n",
    "num_classes = 10\n",
    "height, width, nchannels = 28, 28, 1\n",
    "padding = 'same'\n",
    "\n",
    "batch_size = 100\n",
    "max_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "We will use Keras layers, which are documented [here](https://keras.io/layers/about-keras-layers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace of the tensors shape as it is propagated through the network.\n",
      "Layer name \t Output size\n",
      "----------------------------\n",
      "x_pl \t\t (?, 28, 28, 1)\n",
      "conv1 \t\t (?, 28, 28, 16)\n",
      "pool1 \t\t (?, 14, 14, 16)\n",
      "Flatten \t (?, 3136)\n",
      "denseOut\t (?, 10)\n",
      "Model consits of  31786 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "filters_1 = 16\n",
    "kernel_size_1 = (5,5)\n",
    "pool_size_1 = (2,2)\n",
    "\n",
    "x_pl = tf.placeholder(tf.float32, [None, height, width, nchannels], name='xPlaceholder')\n",
    "y_pl = tf.placeholder(tf.float64, [None, num_classes], name='yPlaceholder')\n",
    "y_pl = tf.cast(y_pl, tf.float32)\n",
    "\n",
    "print('Trace of the tensors shape as it is propagated through the network.')\n",
    "print('Layer name \\t Output size')\n",
    "print('----------------------------')\n",
    "\n",
    "with tf.variable_scope('convLayer1'):\n",
    "    conv1 = Conv2D(filters_1, kernel_size_1, strides=(1,1), padding=padding, activation='relu')\n",
    "    print('x_pl \\t\\t', x_pl.get_shape())\n",
    "    x = conv1(x_pl)\n",
    "    print('conv1 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=pool_size_1, strides=None, padding=padding)\n",
    "    x = pool1(x)\n",
    "    print('pool1 \\t\\t', x.get_shape())\n",
    "    x = flatten(x)\n",
    "    print('Flatten \\t', x.get_shape())\n",
    "\n",
    "with tf.variable_scope('output_layer'):\n",
    "    denseOut = Dense(units=num_classes, activation='softmax')\n",
    "\n",
    "    y = denseOut(x)\n",
    "    print('denseOut\\t', y.get_shape())    \n",
    "\n",
    "print('Model consits of ', utils.num_params(), 'trainable parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    # computing cross entropy per sample\n",
    "    cross_entropy = -tf.reduce_sum(y_pl * tf.log(y+1e-8), reduction_indices=[1])\n",
    "\n",
    "    # averaging over samples\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "with tf.variable_scope('training'):\n",
    "    # defining our optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "    # applying the gradients\n",
    "    train_op = optimizer.minimize(cross_entropy)\n",
    "\n",
    "with tf.variable_scope('performance'):\n",
    "    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n",
    "    correct_prediction = tf.equal(tf.argmax(y, axis=1), tf.argmax(y_pl, axis=1))\n",
    "\n",
    "    # averaging the one-hot encoded vector\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.24241406532567455&quot;).pbtxt = 'node {\\n  name: &quot;xPlaceholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 28\\n        }\\n        dim {\\n          size: 28\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;yPlaceholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;yPlaceholder&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_DOUBLE\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.11881770193576813\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.11881770193576813\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 87654321\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 2502494\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/max&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/RandomUniform&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/mul&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;convLayer1/conv2d/1/kernel&quot;\\n  input: &quot;convLayer1/conv2d/1/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;convLayer1/conv2d/1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;convLayer1/conv2d/1/bias&quot;\\n  input: &quot;convLayer1/conv2d/1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;convLayer1/conv2d/1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/convolution/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/convolution/dilation_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/convolution&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;xPlaceholder&quot;\\n  input: &quot;convLayer1/conv2d/1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;convLayer1/conv2d/1/convolution&quot;\\n  input: &quot;convLayer1/conv2d/1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/conv2d/1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;convLayer1/conv2d/1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/max/pooling2d_1/MaxPool&quot;\\n  op: &quot;MaxPool&quot;\\n  input: &quot;convLayer1/conv2d/1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;convLayer1/max/pooling2d_1/MaxPool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Slice/begin&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Slice/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;convLayer1/Flatten/Shape&quot;\\n  input: &quot;convLayer1/Flatten/Slice/begin&quot;\\n  input: &quot;convLayer1/Flatten/Slice/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Slice/1/begin&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Slice/1/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 3\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Slice/1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;convLayer1/Flatten/Shape&quot;\\n  input: &quot;convLayer1/Flatten/Slice/1/begin&quot;\\n  input: &quot;convLayer1/Flatten/Slice/1/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;convLayer1/Flatten/Slice/1&quot;\\n  input: &quot;convLayer1/Flatten/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;convLayer1/Flatten/Prod&quot;\\n  input: &quot;convLayer1/Flatten/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;convLayer1/Flatten/Slice&quot;\\n  input: &quot;convLayer1/Flatten/ExpandDims&quot;\\n  input: &quot;convLayer1/Flatten/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;convLayer1/Flatten/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;convLayer1/max/pooling2d_1/MaxPool&quot;\\n  input: &quot;convLayer1/Flatten/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;@\\\\014\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.04367131367325783\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.04367131367325783\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 87654321\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 447393\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/max&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/RandomUniform&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/mul&quot;\\n  input: &quot;output/layer/dense_1/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3136\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;output/layer/dense_1/kernel&quot;\\n  input: &quot;output/layer/dense_1/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;output/layer/dense_1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;output/layer/dense_1/bias&quot;\\n  input: &quot;output/layer/dense_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;output/layer/dense_1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;convLayer1/Flatten/Reshape&quot;\\n  input: &quot;output/layer/dense_1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;output/layer/dense_1/MatMul&quot;\\n  input: &quot;output/layer/dense_1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;output/layer/dense_1/Softmax&quot;\\n  op: &quot;Softmax&quot;\\n  input: &quot;output/layer/dense_1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/add/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999993922529e-09\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;output/layer/dense_1/Softmax&quot;\\n  input: &quot;loss/add/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Log&quot;\\n  op: &quot;Log&quot;\\n  input: &quot;loss/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cast&quot;\\n  input: &quot;loss/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Sum/reduction/indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;loss/mul&quot;\\n  input: &quot;loss/Sum/reduction/indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;loss/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/Neg&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;training/gradients/Shape&quot;\\n  input: &quot;training/gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/Fill&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/Neg&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Reshape&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/Neg&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Shape_1&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Shape_2&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Prod_1&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Prod&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Mean/grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Tile&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Neg/grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;training/gradients/loss/Mean/grad/truediv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss/Sum/reduction/indices&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/add&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/range/start&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Size&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Shape_1&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/range&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/mod&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Shape&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/DynamicStitch&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Shape&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/loss/Neg/grad/Neg&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Sum/grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Reshape&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Shape&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Tile&quot;\\n  input: &quot;loss/Log&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/gradients/loss/mul/grad/mul&quot;\\n  input: &quot;training/gradients/loss/mul/grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Sum&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cast&quot;\\n  input: &quot;training/gradients/loss/Sum/grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/gradients/loss/mul/grad/mul_1&quot;\\n  input: &quot;training/gradients/loss/mul/grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Sum_1&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/gradients/loss/mul/grad/Reshape&quot;\\n  input: &quot;^training/gradients/loss/mul/grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Reshape&quot;\\n  input: &quot;^training/gradients/loss/mul/grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/loss/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/mul/grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/loss/mul/grad/Reshape_1&quot;\\n  input: &quot;^training/gradients/loss/mul/grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/loss/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Log/grad/Reciprocal&quot;\\n  op: &quot;Reciprocal&quot;\\n  input: &quot;loss/add&quot;\\n  input: &quot;^training/gradients/loss/mul/grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/Log/grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/gradients/loss/mul/grad/tuple/control_dependency_1&quot;\\n  input: &quot;training/gradients/loss/Log/grad/Reciprocal&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;output/layer/dense_1/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;training/gradients/loss/add/grad/Shape&quot;\\n  input: &quot;training/gradients/loss/add/grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/gradients/loss/Log/grad/mul&quot;\\n  input: &quot;training/gradients/loss/add/grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/loss/add/grad/Sum&quot;\\n  input: &quot;training/gradients/loss/add/grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/gradients/loss/Log/grad/mul&quot;\\n  input: &quot;training/gradients/loss/add/grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/loss/add/grad/Sum_1&quot;\\n  input: &quot;training/gradients/loss/add/grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/gradients/loss/add/grad/Reshape&quot;\\n  input: &quot;^training/gradients/loss/add/grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/loss/add/grad/Reshape&quot;\\n  input: &quot;^training/gradients/loss/add/grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/loss/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/loss/add/grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/loss/add/grad/Reshape_1&quot;\\n  input: &quot;^training/gradients/loss/add/grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/loss/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/gradients/loss/add/grad/tuple/control_dependency&quot;\\n  input: &quot;output/layer/dense_1/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/mul&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Sum&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;training/gradients/loss/add/grad/tuple/control_dependency&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/Softmax_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/sub&quot;\\n  input: &quot;output/layer/dense_1/Softmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/Softmax_grad/mul_1&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/Softmax_grad/mul_1&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/output_layer/dense_1/Softmax_grad/mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/output_layer/dense_1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;output/layer/dense_1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;convLayer1/Flatten/Reshape&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/output_layer/dense_1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/output/layer/dense_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^training/gradients/output/layer/dense_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/output_layer/dense_1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/Flatten/Reshape/grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;convLayer1/max/pooling2d_1/MaxPool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/Flatten/Reshape/grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;training/gradients/convLayer1/Flatten/Reshape/grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/max/pooling2d_1/MaxPool_grad/MaxPoolGrad&quot;\\n  op: &quot;MaxPoolGrad&quot;\\n  input: &quot;convLayer1/conv2d/1/Relu&quot;\\n  input: &quot;convLayer1/max/pooling2d_1/MaxPool&quot;\\n  input: &quot;training/gradients/convLayer1/Flatten/Reshape/grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;training/gradients/convLayer1/max/pooling2d_1/MaxPool_grad/MaxPoolGrad&quot;\\n  input: &quot;convLayer1/conv2d/1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/convLayer1/conv2d_1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/convLayer1/conv2d_1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;xPlaceholder&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Shape&quot;\\n  input: &quot;convLayer1/conv2d/1/kernel/read&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\020\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;xPlaceholder&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Shape_1&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/convolution_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/convolution_grad/Conv2DBackpropFilter&quot;\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/convolution_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/convLayer1/conv2d_1/convolution_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^training/gradients/convLayer1/conv2d/1/convolution_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@training/gradients/convLayer1/conv2d_1/convolution_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta1/power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta1/power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta1/power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/beta1/power&quot;\\n  input: &quot;training/beta1/power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta1/power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/beta1/power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta2/power/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.9990000128746033\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta2/power&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta2/power/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/beta2/power&quot;\\n  input: &quot;training/beta2/power/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/beta2/power/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/beta2/power&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 1\\n        }\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam_1&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 16\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 16\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam_1&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/convLayer1/conv2d/1/bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3136\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3136\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3136\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 3136\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam_1&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/kernel/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam_1/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam_1&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam_1/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/output/layer/dense_1/bias/Adam_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/learning/rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/beta1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/beta2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.9990000128746033\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/epsilon&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 9.99999993922529e-09\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/update/convLayer1/conv2d_1/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;convLayer1/conv2d/1/kernel&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam&quot;\\n  input: &quot;training/convLayer1/conv2d/1/kernel/Adam_1&quot;\\n  input: &quot;training/beta1/power/read&quot;\\n  input: &quot;training/beta2/power/read&quot;\\n  input: &quot;training/Adam/learning/rate&quot;\\n  input: &quot;training/Adam/beta1&quot;\\n  input: &quot;training/Adam/beta2&quot;\\n  input: &quot;training/Adam/epsilon&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/convolution_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/update/convLayer1/conv2d_1/bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;convLayer1/conv2d/1/bias&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam&quot;\\n  input: &quot;training/convLayer1/conv2d/1/bias/Adam_1&quot;\\n  input: &quot;training/beta1/power/read&quot;\\n  input: &quot;training/beta2/power/read&quot;\\n  input: &quot;training/Adam/learning/rate&quot;\\n  input: &quot;training/Adam/beta1&quot;\\n  input: &quot;training/Adam/beta2&quot;\\n  input: &quot;training/Adam/epsilon&quot;\\n  input: &quot;training/gradients/convLayer1/conv2d/1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/update/output_layer/dense_1/kernel/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;output/layer/dense_1/kernel&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam&quot;\\n  input: &quot;training/output/layer/dense_1/kernel/Adam_1&quot;\\n  input: &quot;training/beta1/power/read&quot;\\n  input: &quot;training/beta2/power/read&quot;\\n  input: &quot;training/Adam/learning/rate&quot;\\n  input: &quot;training/Adam/beta1&quot;\\n  input: &quot;training/Adam/beta2&quot;\\n  input: &quot;training/Adam/epsilon&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/update/output_layer/dense_1/bias/ApplyAdam&quot;\\n  op: &quot;ApplyAdam&quot;\\n  input: &quot;output/layer/dense_1/bias&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam&quot;\\n  input: &quot;training/output/layer/dense_1/bias/Adam_1&quot;\\n  input: &quot;training/beta1/power/read&quot;\\n  input: &quot;training/beta2/power/read&quot;\\n  input: &quot;training/Adam/learning/rate&quot;\\n  input: &quot;training/Adam/beta1&quot;\\n  input: &quot;training/Adam/beta2&quot;\\n  input: &quot;training/Adam/epsilon&quot;\\n  input: &quot;training/gradients/output/layer/dense_1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@output_layer/dense_1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/beta1/power/read&quot;\\n  input: &quot;training/Adam/beta1&quot;\\n  input: &quot;^training/Adam/update/convLayer1/conv2d_1/kernel/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/convLayer1/conv2d_1/bias/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/output_layer/dense_1/kernel/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/output_layer/dense_1/bias/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/beta1/power&quot;\\n  input: &quot;training/Adam/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/mul/1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;training/beta2/power/read&quot;\\n  input: &quot;training/Adam/beta2&quot;\\n  input: &quot;^training/Adam/update/convLayer1/conv2d_1/kernel/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/convLayer1/conv2d_1/bias/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/output_layer/dense_1/kernel/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/output_layer/dense_1/bias/ApplyAdam&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam/Assign/1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;training/beta2/power&quot;\\n  input: &quot;training/Adam/mul/1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@convLayer1/conv2d_1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;training/Adam&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^training/Adam/update/convLayer1/conv2d_1/kernel/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/convLayer1/conv2d_1/bias/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/output_layer/dense_1/kernel/ApplyAdam&quot;\\n  input: &quot;^training/Adam/update/output_layer/dense_1/bias/ApplyAdam&quot;\\n  input: &quot;^training/Adam/Assign&quot;\\n  input: &quot;^training/Adam/Assign/1&quot;\\n}\\nnode {\\n  name: &quot;performance/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;output/layer/dense_1/Softmax&quot;\\n  input: &quot;performance/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/ArgMax/1/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/ArgMax/1&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;Cast&quot;\\n  input: &quot;performance/ArgMax/1/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;performance/ArgMax&quot;\\n  input: &quot;performance/ArgMax/1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;performance/Equal&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;performance/Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;performance/Cast&quot;\\n  input: &quot;performance/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.24241406532567455&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Launch TensorBoard, and visualize the TF graph\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    tmp_def = utils.rename_nodes(sess.graph_def, lambda s:\"/\".join(s.split('_',1)))\n",
    "    utils.show_graph(tmp_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "#Test the forward pass\n",
    "x_batch, y_batch = mnist_data.train.next_batch(4)\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "# with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    y_pred = sess.run(fetches=y, feed_dict={x_pl: x_batch})\n",
    "\n",
    "assert y_pred.shape == y_batch.shape, \"ERROR the output shape is not as expected!\" \\\n",
    "        + \" Output shape should be \" + str(y.shape) + ' but was ' + str(y_pred.shape)\n",
    "\n",
    "print('Forward pass successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training loop\n",
      "Epoch 1 : Train Loss  0.147, Train acc  0.950,  Valid loss  0.136,  Valid acc  0.962\n",
      "Epoch 2 : Train Loss  0.115, Train acc  0.950,  Valid loss  0.092,  Valid acc  0.974\n",
      "Epoch 3 : Train Loss  0.049, Train acc  0.990,  Valid loss  0.074,  Valid acc  0.977\n",
      "Epoch 4 : Train Loss  0.022, Train acc  1.000,  Valid loss  0.066,  Valid acc  0.980\n",
      "Epoch 5 : Train Loss  0.027, Train acc  0.990,  Valid loss  0.058,  Valid acc  0.983\n",
      "Epoch 6 : Train Loss  0.013, Train acc  1.000,  Valid loss  0.055,  Valid acc  0.984\n",
      "Epoch 7 : Train Loss  0.020, Train acc  1.000,  Valid loss  0.056,  Valid acc  0.983\n",
      "Epoch 8 : Train Loss  0.136, Train acc  0.970,  Valid loss  0.053,  Valid acc  0.985\n",
      "Epoch 9 : Train Loss  0.015, Train acc  1.000,  Valid loss  0.053,  Valid acc  0.985\n",
      "Epoch 10 : Train Loss  0.043, Train acc  0.980,  Valid loss  0.052,  Valid acc  0.987\n",
      "Test Loss  0.048, Test acc  0.986\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "valid_loss, valid_accuracy = [], []\n",
    "train_loss, train_accuracy = [], []\n",
    "test_loss, test_accuracy = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Begin training loop')\n",
    "\n",
    "    try:\n",
    "        while mnist_data.train.epochs_completed < max_epochs:\n",
    "            _train_loss, _train_accuracy = [], []\n",
    "            \n",
    "            ## Run train op\n",
    "            x_batch, y_batch = mnist_data.train.next_batch(batch_size)\n",
    "            fetches_train = [train_op, cross_entropy, accuracy]\n",
    "            feed_dict_train = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _, _loss, _acc = sess.run(fetches_train, feed_dict_train)\n",
    "            \n",
    "            _train_loss.append(_loss)\n",
    "            _train_accuracy.append(_acc)\n",
    "            \n",
    "            ## Compute validation loss and accuracy\n",
    "            if mnist_data.train.epochs_completed % 1 == 0 \\\n",
    "                    and mnist_data.train._index_in_epoch <= batch_size:\n",
    "                train_loss.append(np.mean(_train_loss))\n",
    "                train_accuracy.append(np.mean(_train_accuracy))\n",
    "\n",
    "                fetches_valid = [cross_entropy, accuracy]\n",
    "                \n",
    "                feed_dict_valid = {x_pl: mnist_data.validation.images, y_pl: mnist_data.validation.labels}\n",
    "                _loss, _acc = sess.run(fetches_valid, feed_dict_valid)\n",
    "                \n",
    "                valid_loss.append(_loss)\n",
    "                valid_accuracy.append(_acc)\n",
    "                print(\"Epoch {} : Train Loss {:6.3f}, Train acc {:6.3f},  Valid loss {:6.3f},  Valid acc {:6.3f}\".format(\n",
    "                    mnist_data.train.epochs_completed, train_loss[-1], train_accuracy[-1], valid_loss[-1], valid_accuracy[-1]))\n",
    "        \n",
    "        test_epoch = mnist_data.test.epochs_completed\n",
    "        while mnist_data.test.epochs_completed == test_epoch:\n",
    "            x_batch, y_batch = mnist_data.test.next_batch(batch_size)\n",
    "            feed_dict_test = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _loss, _acc = sess.run(fetches_valid, feed_dict_test)\n",
    "            test_loss.append(_loss)\n",
    "            test_accuracy.append(_acc)\n",
    "        print('Test Loss {:6.3f}, Test acc {:6.3f}'.format(\n",
    "                    np.mean(test_loss), np.mean(test_accuracy)))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.text.Text at 0x231370b0d30>,\n",
       " <matplotlib.text.Text at 0x23134d4f908>,\n",
       " (0.75, 1.03))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0YIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2313709db70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = np.arange(len(train_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_accuracy,'r', epoch, valid_accuracy,'b')\n",
    "plt.legend(['Train Acc','Val Acc'], loc=4)\n",
    "plt.xlabel('Epochs'), plt.ylabel('Acc'), plt.ylim([0.75,1.03])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> EXE 1.1 </span> Manual calculations\n",
    "\n",
    "![](images/conv_exe.png)\n",
    "\n",
    "\n",
    "\n",
    "1. Manually convolve the input, and compute the convolved features. No padding and no strieds.\n",
    "1. Perform `2x2` max pooling on the convolved features. Stride of 2.\n",
    "\n",
    "___\n",
    "\n",
    "<span style=\"color:blue\"> Answer: </span>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We just place the kernel matrix on top of the pixels and multiply, just as shown in the first notebook from week 2.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    y_{0,0} &= 1 \\cdot 2 +2 \\cdot 3 = 8 \\\\\n",
    "    y_{1,0} &= 2 \\cdot 1 + 2 \\cdot 1 + 2 \\cdot 2 + 2 \\cdot 3 = 14 \\\\\n",
    "    y_{0,1} &= 2 \\cdot 2 + 2 \\cdot 2 + 3 \\cdot 3 + 1 \\cdot 1 + 2 \\cdot 2 = 20 \\\\\n",
    "    y_{1,1} &= 2 \\cdot 2 + 2 \\cdot 1 + 2 \\cdot 2 + 3 \\cdot 2 + 3 \\cdot 3 = 25\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We can verify the result with scipy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8 20]\n",
      " [14 25]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 0, 0, 1],[0, 0,1,2],[0,0,2,3],[0,1,2,3]])\n",
    "k=np.array([[0,0,2],[0,1,2],[0,2,3]])\n",
    "k = np.rot90(k, 2)\n",
    "y = signal.convolve2d(x, k, 'valid')\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Performing 2x2 max pooling on a 2x2 matrix will just give us the maximum value of that matrix, here 25, even with a stride of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:red\"> EXE 1.2 </span> Reducing the resolution\n",
    "One of the important features of convolutional networks are their ability to reduce the spatial resolution, while retaining the important features.\n",
    "Effectively this gives a local translational invariance and reduces the computation. \n",
    "This is most often done with **maxpooling** or by using strides.\n",
    "\n",
    "1. Using only convolutional layers and pooling operations reduce the feature map size to `1x1xF`.\n",
    "    * The number of feature maps, `F`, is up to you.\n",
    "\n",
    "___\n",
    "\n",
    "<span style=\"color:blue\"> Write down what you did: </span>\n",
    "\n",
    "``` \n",
    "Paste your code here\n",
    "```\n",
    "\n",
    "\n",
    "``` \n",
    "Paste the trace of the tensors shape as it is propagated through the network here\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">I need to import this again, otherwise the training will fail.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', \n",
    "                                       one_hot=True,   # Convert the labels into one hot encoding\n",
    "                                       dtype='float32', # rescale images to `[0, 1]`\n",
    "                                       reshape=False, # Don't flatten the images to vectors\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">I define the network with the parameters given here at the top.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace of the tensors shape as it is propagated through the network.\n",
      "Layer name \t Output size\n",
      "----------------------------\n",
      "x_pl \t\t (?, 28, 28, 1)\n",
      "conv1 \t\t (?, 28, 28, 32)\n",
      "pool1 \t\t (?, 14, 14, 32)\n",
      "conv2 \t\t (?, 14, 14, 64)\n",
      "pool2 \t\t (?, 7, 7, 64)\n",
      "conv3 \t\t (?, 7, 7, 14)\n",
      "pool3 \t\t (?, 1, 1, 14)\n",
      "Flatten \t (?, 14)\n",
      "denseOut\t (?, 10)\n",
      "Model consits of  27044 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "filters_1 = 32\n",
    "kernel_size_1 = (3,3)\n",
    "pool_size_1 = (2,2)\n",
    "\n",
    "filters_2 = 64\n",
    "kernel_size_2 = (3,3)\n",
    "pool_size_2 = (2, 2)\n",
    "\n",
    "filters_3 = 14\n",
    "kernel_size_3 = (3,3)\n",
    "pool_size_3 = (7, 7)\n",
    "\n",
    "x_pl = tf.placeholder(tf.float32, [None, height, width, nchannels], name='xPlaceholder')\n",
    "y_pl = tf.placeholder(tf.float64, [None, num_classes], name='yPlaceholder')\n",
    "y_pl = tf.cast(y_pl, tf.float32)\n",
    "\n",
    "print('Trace of the tensors shape as it is propagated through the network.')\n",
    "print('Layer name \\t Output size')\n",
    "print('----------------------------')\n",
    "\n",
    "with tf.variable_scope('convLayer1'):\n",
    "    conv1 = Conv2D(filters_1, kernel_size_1, strides=(1,1), padding=padding, activation='relu')\n",
    "    print('x_pl \\t\\t', x_pl.get_shape())\n",
    "    x = conv1(x_pl)\n",
    "    print('conv1 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=pool_size_1, strides=None, padding=padding)\n",
    "    x = pool1(x)\n",
    "    print('pool1 \\t\\t', x.get_shape())\n",
    "\n",
    "with tf.variable_scope('convLayer2'):\n",
    "    conv2 = Conv2D(filters_2, kernel_size_2, strides=(1,1), padding=padding, activation='relu')\n",
    "    x = conv2(x)\n",
    "    print('conv2 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=pool_size_2, strides=None, padding=padding)\n",
    "    x = pool2(x)\n",
    "    print('pool2 \\t\\t', x.get_shape())\n",
    "    \n",
    "with tf.variable_scope('convLayer3'):\n",
    "    conv3 = Conv2D(filters_3, kernel_size_3, strides=(1,1), padding=padding, activation='relu')\n",
    "    x = conv3(x)\n",
    "    print('conv3 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool3 = MaxPooling2D(pool_size=pool_size_3, strides=None, padding=padding)\n",
    "    x = pool3(x)\n",
    "    print('pool3 \\t\\t', x.get_shape())\n",
    "\n",
    "    x = flatten(x)\n",
    "    print('Flatten \\t', x.get_shape())     \n",
    "\n",
    "with tf.variable_scope('output_layer'):\n",
    "    denseOut = Dense(units=num_classes, activation='softmax')\n",
    "\n",
    "    y = denseOut(x)\n",
    "    print('denseOut\\t', y.get_shape())    \n",
    "\n",
    "print('Model consits of ', utils.num_params(), 'trainable parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">To get 1x1xF, I just maxpool 7x7 (size of what we have before pool3)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    # computing cross entropy per sample\n",
    "    cross_entropy = -tf.reduce_sum(y_pl * tf.log(y+1e-8), reduction_indices=[1])\n",
    "\n",
    "    # averaging over samples\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "with tf.variable_scope('training'):\n",
    "    # defining our optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "    # applying the gradients\n",
    "    train_op = optimizer.minimize(cross_entropy)\n",
    "\n",
    "with tf.variable_scope('performance'):\n",
    "    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n",
    "    correct_prediction = tf.equal(tf.argmax(y, axis=1), tf.argmax(y_pl, axis=1))\n",
    "\n",
    "    # averaging the one-hot encoded vector\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Add saver op to restore the model for prediction  \n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Finally, we can train the network</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training loop\n",
      "Epoch 0 : Train Loss  2.295, Train acc  0.060,  Valid loss  2.310,  Valid acc  0.104\n",
      "Epoch 1 : Train Loss  0.083, Train acc  0.980,  Valid loss  0.151,  Valid acc  0.955\n",
      "Epoch 2 : Train Loss  0.116, Train acc  0.960,  Valid loss  0.113,  Valid acc  0.966\n",
      "Epoch 3 : Train Loss  0.077, Train acc  0.970,  Valid loss  0.089,  Valid acc  0.975\n",
      "Epoch 4 : Train Loss  0.089, Train acc  0.970,  Valid loss  0.071,  Valid acc  0.978\n",
      "Epoch 5 : Train Loss  0.111, Train acc  0.970,  Valid loss  0.073,  Valid acc  0.980\n",
      "Epoch 6 : Train Loss  0.066, Train acc  0.970,  Valid loss  0.062,  Valid acc  0.980\n",
      "Epoch 7 : Train Loss  0.065, Train acc  0.980,  Valid loss  0.052,  Valid acc  0.985\n",
      "Epoch 8 : Train Loss  0.018, Train acc  1.000,  Valid loss  0.053,  Valid acc  0.983\n",
      "Epoch 9 : Train Loss  0.061, Train acc  0.970,  Valid loss  0.057,  Valid acc  0.981\n",
      "Epoch 10 : Train Loss  0.025, Train acc  0.990,  Valid loss  0.052,  Valid acc  0.983\n",
      "Test Loss  0.049, Test acc  0.986\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "batch_size = 100\n",
    "max_epochs = 10\n",
    "\n",
    "valid_loss, valid_accuracy = [], []\n",
    "train_loss, train_accuracy = [], []\n",
    "test_loss, test_accuracy = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Begin training loop')\n",
    "\n",
    "    try:\n",
    "        while mnist_data.train.epochs_completed < max_epochs:\n",
    "            _train_loss, _train_accuracy = [], []\n",
    "            \n",
    "            ## Run train op\n",
    "            x_batch, y_batch = mnist_data.train.next_batch(batch_size)\n",
    "            fetches_train = [train_op, cross_entropy, accuracy]\n",
    "            feed_dict_train = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _, _loss, _acc = sess.run(fetches_train, feed_dict_train)\n",
    "            \n",
    "            _train_loss.append(_loss)\n",
    "            _train_accuracy.append(_acc)\n",
    "            \n",
    "\n",
    "            ## Compute validation loss and accuracy\n",
    "            if mnist_data.train.epochs_completed % 1 == 0 \\\n",
    "                    and mnist_data.train._index_in_epoch <= batch_size:\n",
    "                train_loss.append(np.mean(_train_loss))\n",
    "                train_accuracy.append(np.mean(_train_accuracy))\n",
    "\n",
    "                fetches_valid = [cross_entropy, accuracy]\n",
    "                \n",
    "                feed_dict_valid = {x_pl: mnist_data.validation.images, y_pl: mnist_data.validation.labels}\n",
    "                _loss, _acc = sess.run(fetches_valid, feed_dict_valid)\n",
    "                \n",
    "                valid_loss.append(_loss)\n",
    "                valid_accuracy.append(_acc)\n",
    "                print(\"Epoch {} : Train Loss {:6.3f}, Train acc {:6.3f},  Valid loss {:6.3f},  Valid acc {:6.3f}\".format(\n",
    "                    mnist_data.train.epochs_completed, train_loss[-1], train_accuracy[-1], valid_loss[-1], valid_accuracy[-1]))\n",
    "        \n",
    "        \n",
    "        test_epoch = mnist_data.test.epochs_completed\n",
    "        while mnist_data.test.epochs_completed == test_epoch:\n",
    "            x_batch, y_batch = mnist_data.test.next_batch(batch_size)\n",
    "            feed_dict_test = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _loss, _acc = sess.run(fetches_valid, feed_dict_test)\n",
    "            test_loss.append(_loss)\n",
    "            test_accuracy.append(_acc)\n",
    "        print('Test Loss {:6.3f}, Test acc {:6.3f}'.format(\n",
    "                    np.mean(test_loss), np.mean(test_accuracy)))\n",
    "        \n",
    "        saver.save(sess, './mnist_cnn')\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We can then plot the validation and trianing accuracy over time.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.text.Text at 0x2a5a226c9e8>,\n",
       " <matplotlib.text.Text at 0x2a5a27fc978>,\n",
       " (0.75, 1.03))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXgoLERHJ6/8DaEA/UdAXucoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a5a223e128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = np.arange(len(train_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_accuracy,'r', epoch, valid_accuracy,'b')\n",
    "plt.legend(['Train Acc','Val Acc'], loc=4)\n",
    "plt.xlabel('Epochs'), plt.ylabel('Acc'), plt.ylim([0.75,1.03])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We can then make predictions on the test set</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist_cnn\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:    \n",
    "    saver.restore(sess, './mnist_cnn')\n",
    "    feed_dict_valid = {x_pl: mnist_data.test.images, y_pl: mnist_data.test.labels}\n",
    "\n",
    "    # deciding which parts to fetch\n",
    "    fetches_valid = [accuracy]          \n",
    "\n",
    "    # running the validation\n",
    "    test_acc = sess.run(fetches=fetches_valid, feed_dict=feed_dict_valid)\n",
    "    \n",
    "    y_pred = pred(mnist_data.test.images, sess)    # Get predictions\n",
    "    \n",
    "    y_pred_1 = np.zeros_like(y_pred) # Make new matrix to contain one-hot encoded values of y_pred\n",
    "    y_pred_1[np.arange(len(y_pred)), y_pred.argmax(1)] = 1 # Sets max to 1 and everything else to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy of the network is [0.98560005]\n"
     ]
    }
   ],
   "source": [
    "print('The test accuracy of the network is {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">So the accuracy of the network is 98.6 % on the test set.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> EXE 1.3 </span> Play around with the network.\n",
    "The MNIST dataset is so easy to solve with convolutional networks that it isn't interesting to spend to much time on maximizing performance.\n",
    "A more interesting question is *how few parameters can you solve it with?*\n",
    "\n",
    "1. Try and minimize the number of parameters, while keeping validation accuracy about 95%. Try changing the\n",
    "\n",
    "    * Number of layers\n",
    "    * Number of filters\n",
    "    * Kernel size\n",
    "    * Pooling size\n",
    "1. Once happy take note of the performance, number of parameters (printed automatically), and describe the network below.\n",
    "___\n",
    "\n",
    "\n",
    "<span style=\"color:blue\"> Answer: </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', \n",
    "                                       one_hot=True,   # Convert the labels into one hot encoding\n",
    "                                       dtype='float32', # rescale images to `[0, 1]`\n",
    "                                       reshape=False, # Don't flatten the images to vectors\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">I just remove one layer and reduce the number of filters.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace of the tensors shape as it is propagated through the network.\n",
      "Layer name \t Output size\n",
      "----------------------------\n",
      "x_pl \t\t (?, 28, 28, 1)\n",
      "conv1 \t\t (?, 28, 28, 10)\n",
      "pool1 \t\t (?, 14, 14, 10)\n",
      "conv2 \t\t (?, 14, 14, 14)\n",
      "pool2 \t\t (?, 1, 1, 14)\n",
      "Flatten \t (?, 14)\n",
      "denseOut\t (?, 10)\n",
      "Model consits of  1684 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "filters_1 = 10\n",
    "kernel_size_1 = (5,5)\n",
    "pool_size_1 = (2,2)\n",
    "\n",
    "filters_2 = 14\n",
    "kernel_size_2 = (3,3)\n",
    "pool_size_2 = (filters_2, filters_2)\n",
    "\n",
    "x_pl = tf.placeholder(tf.float32, [None, height, width, nchannels], name='xPlaceholder')\n",
    "y_pl = tf.placeholder(tf.float64, [None, num_classes], name='yPlaceholder')\n",
    "y_pl = tf.cast(y_pl, tf.float32)\n",
    "\n",
    "print('Trace of the tensors shape as it is propagated through the network.')\n",
    "print('Layer name \\t Output size')\n",
    "print('----------------------------')\n",
    "\n",
    "with tf.variable_scope('convLayer1'):\n",
    "    conv1 = Conv2D(filters_1, kernel_size_1, strides=(1,1), padding=padding, activation='relu')\n",
    "    print('x_pl \\t\\t', x_pl.get_shape())\n",
    "    x = conv1(x_pl)\n",
    "    print('conv1 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=pool_size_1, strides=None, padding=padding)\n",
    "    x = pool1(x)\n",
    "    print('pool1 \\t\\t', x.get_shape())\n",
    "    \n",
    "with tf.variable_scope('convLayer2'):\n",
    "    conv2 = Conv2D(filters_2, kernel_size_2, strides=(1,1), padding=padding, activation='relu')\n",
    "    x = conv2(x)\n",
    "    print('conv2 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=pool_size_2, strides=None, padding=padding)\n",
    "    x = pool2(x)\n",
    "    print('pool2 \\t\\t', x.get_shape())\n",
    "    \n",
    "    x = flatten(x)\n",
    "    print('Flatten \\t', x.get_shape()) \n",
    "    \n",
    "with tf.variable_scope('output_layer'):\n",
    "    denseOut = Dense(units=num_classes, activation='softmax')\n",
    "    \n",
    "    y = denseOut(x)\n",
    "    print('denseOut\\t', y.get_shape())    \n",
    "\n",
    "print('Model consits of ', utils.num_params(), 'trainable parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">So now, we only have 1684 parameters.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    # computing cross entropy per sample\n",
    "    cross_entropy = -tf.reduce_sum(y_pl * tf.log(y+1e-8), reduction_indices=[1])\n",
    "\n",
    "    # averaging over samples\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "with tf.variable_scope('training'):\n",
    "    # defining our optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "    # applying the gradients\n",
    "    train_op = optimizer.minimize(cross_entropy)\n",
    "\n",
    "with tf.variable_scope('performance'):\n",
    "    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n",
    "    correct_prediction = tf.equal(tf.argmax(y, axis=1), tf.argmax(y_pl, axis=1))\n",
    "\n",
    "    # averaging the one-hot encoded vector\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "# Add saver op to restore the model for prediction  \n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training loop\n",
      "Epoch 0 : Train Loss  2.327, Train acc  0.110,  Valid loss  2.327,  Valid acc  0.112\n",
      "Epoch 1 : Train Loss  0.583, Train acc  0.840,  Valid loss  0.560,  Valid acc  0.836\n",
      "Epoch 2 : Train Loss  0.462, Train acc  0.880,  Valid loss  0.361,  Valid acc  0.896\n",
      "Epoch 3 : Train Loss  0.342, Train acc  0.880,  Valid loss  0.291,  Valid acc  0.917\n",
      "Epoch 4 : Train Loss  0.307, Train acc  0.920,  Valid loss  0.254,  Valid acc  0.924\n",
      "Epoch 5 : Train Loss  0.304, Train acc  0.890,  Valid loss  0.237,  Valid acc  0.929\n",
      "Epoch 6 : Train Loss  0.218, Train acc  0.910,  Valid loss  0.218,  Valid acc  0.935\n",
      "Epoch 7 : Train Loss  0.155, Train acc  0.970,  Valid loss  0.202,  Valid acc  0.939\n",
      "Epoch 8 : Train Loss  0.230, Train acc  0.940,  Valid loss  0.188,  Valid acc  0.943\n",
      "Epoch 9 : Train Loss  0.199, Train acc  0.960,  Valid loss  0.179,  Valid acc  0.944\n",
      "Epoch 10 : Train Loss  0.226, Train acc  0.930,  Valid loss  0.173,  Valid acc  0.946\n",
      "Test Loss  0.191, Test acc  0.940\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "batch_size = 100\n",
    "max_epochs = 10\n",
    "\n",
    "valid_loss, valid_accuracy = [], []\n",
    "train_loss, train_accuracy = [], []\n",
    "test_loss, test_accuracy = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Begin training loop')\n",
    "\n",
    "    try:\n",
    "        while mnist_data.train.epochs_completed < max_epochs:\n",
    "            _train_loss, _train_accuracy = [], []\n",
    "            \n",
    "            ## Run train op\n",
    "            x_batch, y_batch = mnist_data.train.next_batch(batch_size)\n",
    "            fetches_train = [train_op, cross_entropy, accuracy]\n",
    "            feed_dict_train = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _, _loss, _acc = sess.run(fetches_train, feed_dict_train)\n",
    "            \n",
    "            _train_loss.append(_loss)\n",
    "            _train_accuracy.append(_acc)\n",
    "            \n",
    "\n",
    "            ## Compute validation loss and accuracy\n",
    "            if mnist_data.train.epochs_completed % 1 == 0 \\\n",
    "                    and mnist_data.train._index_in_epoch <= batch_size:\n",
    "                train_loss.append(np.mean(_train_loss))\n",
    "                train_accuracy.append(np.mean(_train_accuracy))\n",
    "\n",
    "                fetches_valid = [cross_entropy, accuracy]\n",
    "                \n",
    "                feed_dict_valid = {x_pl: mnist_data.validation.images, y_pl: mnist_data.validation.labels}\n",
    "                _loss, _acc = sess.run(fetches_valid, feed_dict_valid)\n",
    "                \n",
    "                valid_loss.append(_loss)\n",
    "                valid_accuracy.append(_acc)\n",
    "                print(\"Epoch {} : Train Loss {:6.3f}, Train acc {:6.3f},  Valid loss {:6.3f},  Valid acc {:6.3f}\".format(\n",
    "                    mnist_data.train.epochs_completed, train_loss[-1], train_accuracy[-1], valid_loss[-1], valid_accuracy[-1]))\n",
    "        \n",
    "        test_epoch = mnist_data.test.epochs_completed\n",
    "        while mnist_data.test.epochs_completed == test_epoch:\n",
    "            x_batch, y_batch = mnist_data.test.next_batch(batch_size)\n",
    "            feed_dict_test = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _loss, _acc = sess.run(fetches_valid, feed_dict_test)\n",
    "            test_loss.append(_loss)\n",
    "            test_accuracy.append(_acc)\n",
    "        print('Test Loss {:6.3f}, Test acc {:6.3f}'.format(\n",
    "                    np.mean(test_loss), np.mean(test_accuracy)))\n",
    "        \n",
    "        saver.save(sess, './mnist_cnn')\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.text.Text at 0x2a5acf06a20>,\n",
       " <matplotlib.text.Text at 0x2a5ad91ba20>,\n",
       " (0.75, 1.03))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQkrv8P1jMMN3olb/wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a5ad44a550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = np.arange(len(train_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_accuracy,'r', epoch, valid_accuracy,'b')\n",
    "plt.legend(['Train Acc','Val Acc'], loc=4)\n",
    "plt.xlabel('Epochs'), plt.ylabel('Acc'), plt.ylim([0.75,1.03])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We can then make predictions on the test set in order to obtain the accuracy on the test set.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mnist_cnn\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:    \n",
    "    saver.restore(sess, './mnist_cnn')\n",
    "    feed_dict_valid = {x_pl: mnist_data.test.images, y_pl: mnist_data.test.labels}\n",
    "\n",
    "    # deciding which parts to fetch\n",
    "    fetches_valid = [accuracy]          \n",
    "\n",
    "    # running the validation\n",
    "    test_acc = sess.run(fetches=fetches_valid, feed_dict=feed_dict_valid)\n",
    "    \n",
    "    y_pred = pred(mnist_data.test.images, sess)    # Get predictions\n",
    "    \n",
    "    y_pred_1 = np.zeros_like(y_pred) # Make new matrix to contain one-hot encoded values of y_pred\n",
    "    y_pred_1[np.arange(len(y_pred)), y_pred.argmax(1)] = 1 # Sets max to 1 and everything else to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy of the network is [0.94010013]\n"
     ]
    }
   ],
   "source": [
    "print('The test accuracy of the network is {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">So the accuracy of the network is 94.01 % on the test set.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> EXE 1.4 </span> Comparing dense and convolutional networks\n",
    "\n",
    "1. Now create a densely connected network (the ones from lab 1), and see how good performance you can get with a similar number of parameters.\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">If you run this notebook, you may be required to restart the kernel for this section, the first cells then need to be executed again for the variables and modules.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', \n",
    "                                       one_hot=True,   # Convert the labels into one hot encoding\n",
    "                                       dtype='float32', # rescale images to `[0, 1]`\n",
    "                                       reshape=True, # Flatten the images to vectors\n",
    "                                      )\n",
    "\n",
    "num_features = mnist_data.train.images[0].shape[0]\n",
    "num_classes = mnist_data.train.labels[0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">As a vector, we have 784 features, this means that with just 2 neurons in the hidden layer, we will have 1568 weights.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "session = K.get_session()\n",
    "if model is not None:\n",
    "    model.reset_states() # Reset graph\n",
    "\n",
    "n_hidden1 = 2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(n_hidden1, activation='elu', input_dim=num_features))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 2)                 1570      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                30        \n",
      "=================================================================\n",
      "Total params: 1,600\n",
      "Trainable params: 1,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We then train and print the validation accurcary.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Developer\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.47879998505115506\n",
      "Validation accuracy: 0.5665999782085419\n",
      "Validation accuracy: 0.6363999879360199\n",
      "Validation accuracy: 0.6613999807834625\n",
      "Validation accuracy: 0.6923999845981598\n",
      "Validation accuracy: 0.6967999792098999\n",
      "Validation accuracy: 0.7081999790668487\n",
      "Validation accuracy: 0.7125999808311463\n",
      "Validation accuracy: 0.7137999761104584\n",
      "Validation accuracy: 0.7195999789237976\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "#history = model.fit(mnist_data.train.images, mnist_data.train.labels, batch_size=100, epochs=10)\n",
    "\n",
    "for e in range(epochs):\n",
    "    train_loss = model.fit(mnist_data.train.images, mnist_data.train.labels, batch_size=batch_size, nb_epoch=1, verbose = 0)\n",
    "    val_score, val_acc = model.evaluate(mnist_data.validation.images, mnist_data.validation.labels, batch_size=batch_size, verbose = 0)\n",
    "    \n",
    "    print(\"Validation accuracy: {}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">We then obtain the test accuracy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.999282538128\n",
      "Test accuracy: 0.7017\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(mnist_data.test.images, mnist_data.test.labels, verbose=0)\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">So it is significantly worse than the convolutional neural network using approximately the same number of parameters.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Book Exercise](http://neuralnetworksanddeeplearning.com/chap3.html#exercise_35813)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I have provided the link to the exercise in the heading. \n",
    "In the following, I will not write the text in blue since this is only the book exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that $\\sigma ' (z) = \\sigma(z)(1-\\sigma(z))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sigma(z) = \\frac{1}{1+e^{-z}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differentiating gives us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\sigma(z)'&= \\frac{e^{-z}}{(1+e^{-z})^2} \\\\\n",
    "              &= \\frac{1+e^{-z}}{(1+e^{-z})^2} - \\frac{1}{(1+e^{-z})^2} \\\\\n",
    "              &= \\frac{1}{1+e^{-z}} - \\frac{1}{(1+e^{-z})^2} \\\\\n",
    "              &= \\sigma(z) - \\sigma(z)^2 \\\\\n",
    "              &= \\sigma(z) (1- \\sigma(z))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is what we wanted."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
