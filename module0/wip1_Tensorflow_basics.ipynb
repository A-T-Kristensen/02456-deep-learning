{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Basics\n",
    "This Jupyter Notebook contains a very fast introduction to TensorFlow (TF).\n",
    "This introduciton is **VERY** fast, and leaves many topics untouched or under touched, but should give you enough of an introduction to be able to follow the later notebooks.\n",
    "If you want a deeper dive the following are good places to start:\n",
    "\n",
    "#### External resources\n",
    "* [Official getting started material](https://www.tensorflow.org/get_started/) - collection of good tutorials from beginer to very advanced\n",
    "* **[Python API Guides](https://www.tensorflow.org/api_guides/python/array_ops)** - GREAT place to look up TF works! Has some descriptions of how and why to use different parts.\n",
    "* [Documentation](https://www.tensorflow.org/api_docs/python/) - Short and consice descriptions of how everything in TF works.\n",
    "* [LearningTensorFlow.org](http://learningtensorflow.com/getting_started/) - A website dedicated to teaching TF. They have some good tutorials at varying levels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is TensorFlow\n",
    "TensorFlow is a programming system in which you represent computations as graphs.\n",
    "This graph is then compiled to efficient C code.\n",
    "This added layer of abstraction makes it possible to have the same code run seamlessly on both GPU and parallel on CPU. \n",
    "\n",
    "TensorFlow provides multiple APIs. \n",
    "The lowest level API, **TensorFlow Core**, provides you with fine-grained control.\n",
    "Higher level APIs, such as `tf.contrib.learn`, are built on top of TensorFlow Core, are generally faster and easier to use.\n",
    "They help manage data, training, and inference.\n",
    "This guide begins with an introduction to **TensorFlow Core**.\n",
    "Later, in other exercises, we will demonstrate how to use Tensorflow in a way that is closer to how it is used in the real world.\n",
    "\n",
    "**NB**: The some of the API whose names contain `contrib` are still in development, and their interface may change.\n",
    "\n",
    "To use TensorFlow you need to understand how TensorFlow:\n",
    "* Represents computations as graphs.\n",
    "* Executes graphs in the context of Sessions.\n",
    "* Represents data as tensors.\n",
    "* Maintains state with Variables.\n",
    "* Uses feeds and fetches to get data into and out of arbitrary operations.\n",
    "\n",
    "**<span style=\"color:red\">TODO</span>**:\n",
    "Either make sure we cover all this, or tell which part we cover in this section!!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two basic building blocks of TensorFlow are **tensors** and **operations** (called ops for short).\n",
    "* **Tensors**: The edges in the graph\n",
    "    * A Tensor is a typed multi-dimensional array, and are how information flows through the graph.\n",
    "    * Tensors are used for data and parameters\n",
    "* **Ops**: the nodes in the graph \n",
    "    * An op takes zero or more Tensors, performs some computation, and produces zero or more Tensors.\n",
    "\n",
    "A TensorFlow graph is a description of computations. To compute anything, a graph must be launched in a `Session`. A Session places the graph ops onto `Devices`, such as CPUs or GPUs, and provides methods to execute them. These methods return tensors produced by ops as [numpy](http://www.numpy.org/) ndarray objects in Python, and as `tensorflow::Tensor` instances in C and C++.\n",
    "\n",
    "TensorFlow can be used from C, C++, and Python programs, with Python being the most common and best supported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: The ultra basics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import TensorFlow, and some other handy libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join('.', '..')) # Allow us to import shared custom \n",
    "                                         # libraries, like utils.py\n",
    "import utils # contain various helper funcitons that aren't \n",
    "             # important to understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic operations\n",
    "\n",
    "Let us begin with a simple example -- 2D linear regression: $y = ax + b$. Where $x$ is the input, $y$ is the output, and $a,~b$ are the parameters.\n",
    "\n",
    "For starters let us compute $y$ when $a=2$, and $b=-1$ for a couple of different $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Building the computational graph\n",
    "\n",
    "# In case we have already created something: clear it\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create the two variables\n",
    "# The 'name' argument indicates what TF should call the variable internally.\n",
    "# It is a good idea to properly name your ops, as it makes debugging and later analysis much easier!\n",
    "a = tf.Variable(2., name=\"a\")\n",
    "b = tf.Variable(-1., name=\"b\")\n",
    "\n",
    "# Create an x variable, with some numbers\n",
    "x_values = [-2, -1, 0, 1, 2]\n",
    "x_var = tf.Variable(x_values, name=\"xVariable\", dtype=tf.float32)\n",
    "\n",
    "# Define y\n",
    "with tf.name_scope('yFromVariable'): # Give y a name\n",
    "    y_var = a*x_var + b\n",
    "\n",
    "print(y_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What just happened?\n",
    "Why didn't `print(y_var)` print out the answer?\n",
    "\n",
    "You might have expected `y_var` to be the results of `a*x_var + b`, but instead we got an **Tensor** object.\n",
    "This is because before TensorFlow works by first creating a computational graph representation.\n",
    "This graph can then be compiled, which can then be run.\n",
    "This means that `y_var` is a TF **operation**, i.e. a node in the computational graph.\n",
    "\n",
    "Lets compile and run `y_var` now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an operation that will initialize the graph.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# TensorFlow operations are performed by 'Sessions'\n",
    "with tf.Session() as sess:\n",
    "    # Run the operation that initializes the graph. \n",
    "    # We almost always do this as the first thing.\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # Compute y by running the operation\n",
    "    y_output = sess.run(y_var)\n",
    "\n",
    "print('y_output is a ' + str(type(y_output)) + '\\n')\n",
    "\n",
    "# Print the results\n",
    "print('{:4s}  {:4s}'.format('x_var', '  y'))\n",
    "for i in range(len(x_values)):\n",
    "    s = \"{:4.1f} : {:4.1f}\"\n",
    "    print(s.format(x_values[i], y_output[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all well an good, but what if we wanted compute this for another $x$?\n",
    "Right now we have defined `x_var` as a `tf.variable`.\n",
    "This makes changing it cumbersome.\n",
    "A better approach is using `tf.placeholder`, which we will do now.\n",
    "\n",
    "A `placeholder` has 3 important arguments:\n",
    "* **`dtype`** specifying what kind of data we are dealing with. Generally use **tf.float32**, as most GPU's are only optimized for 32 bit floating points\n",
    "* **`shape`** lets TF know the dimensions of the variable. Writing `None` allows us to change the number of dimensions, without having to recompile the graph. This however prevents some optimization, so it should be specified when possible.\n",
    "* **`name`** is what TF will call the placeholder internally. For instance this is the name it will use if the placeholder causes an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create x as a placeholder now!\n",
    "x_ph = tf.placeholder(dtype=tf.float32, shape=[None], name=\"xPlaceholder\")\n",
    "\n",
    "# Define another y, using the placeholder x this time\n",
    "with tf.name_scope('yFromPlaceholder'):\n",
    "    y_ph = a*x_ph + b\n",
    "\n",
    "x_new_values = [-0.2, -0.1, 0, 0.1, 0.2]\n",
    "\n",
    "## Compute y\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    feed_dict = {x_ph : x_new_values}\n",
    "    y_output = sess.run(y_ph, feed_dict=feed_dict)\n",
    "\n",
    "    \n",
    "# Print the results\n",
    "print('{:4s}  {:4s}'.format(' x_ph', '  y'))\n",
    "for i in range(len(x_values)):\n",
    "    s = \"{:4.1f} : {:4.1f}\"\n",
    "    print(s.format(x_new_values[i], y_output[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What just happened?\n",
    "\n",
    "This time, when we created the graph, we created $x$ as a `tf.placeholder`.\n",
    "This means that `x_ph` simply stands in the place of real data.\n",
    "So when we want to compute `y` for a particular value we simply **feed** that value into the graph, using a `feed_dict`.\n",
    "\n",
    "If we wanted to change the values now, we simply need to feed a new value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These **variables** and **palceholders** can be a little hard to wrap your head around at first.\n",
    "It can therefore be a good idea to read up on these:\n",
    "\n",
    "#### External resources:\n",
    "* **Variables**: \n",
    "    [Guide](https://www.tensorflow.org/programmers_guide/variables),\n",
    "    [Documentation](https://www.tensorflow.org/api_docs/python/tf/Variable)\n",
    "* **Placeholders**: \n",
    "    [Documentation](https://www.tensorflow.org/versions/r0.11/api_docs/python/io_ops/placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the graph with TensorBoard\n",
    "\n",
    "Normally TensorBoard is run separately by typing in the command prompt:\n",
    "\n",
    "    tensorboard logdir==<path/to/TensorBoard/logs\n",
    "\n",
    "And then accessed by going to the correct port. Typically `localhost:6006` in your browser of choice.\n",
    "\n",
    "In this notebook however we will show it in-line however.\n",
    "If you want to see how to launch TensorBoard normally see the **`demo_Launching_TensorBoard.ipynb`** notebook, located in this folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you execute the cell below you should see a graph that represents the work we have done so far.\n",
    "\n",
    "Click a node to see its attributes and high level information.\n",
    "**Double click a node to expand it**. Try double clicking on one of the y's.\n",
    "Doing so will show you the operations that are necessary to compute $y$, i.e. a multiplication and an addition.\n",
    "This is especially useful for examining the dimensions of your data as it flows through the graph.\n",
    "\n",
    "The TensorBoard graph visualizer is a great tool for examining your model.\n",
    "It is important to use `tf.name_scope` to dutifully name your variables properly!\n",
    "Otherwise the graph visualizer quickly becomes unwieldy and useless.\n",
    "This takes practice, but it is well worth it.\n",
    "Propper usage of `tf.name_scope` also makes debugging easier, so it is a good habbit to get into.\n",
    "\n",
    "If you are interested in how to embed TensorBoard in the notebook see the `../utils.py` file.\n",
    "There are many details that we didn't cover here, but here is a good place to start:\n",
    "\n",
    "#### External resources\n",
    "* **TensorBoard**: \n",
    "    [Graph visualization](https://www.tensorflow.org/get_started/graph_viz), \n",
    "    [Visualizing Learning](https://www.tensorflow.org/get_started/summaries_and_tensorboard), \n",
    "    [Embedding Visualization](https://www.tensorflow.org/get_started/embedding_viz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Launch TensorBoard, and visualize the TF graph\n",
    "tmp_def = utils.rename_nodes(sess.graph_def, lambda s:\"/\".join(s.split('_',1)))\n",
    "utils.show_graph(tmp_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini-assignment**: \n",
    "Try and change the argument in `tf.name_scope` when defining `y_var` and `y_ph` to `y_variable`, and `y_placeholder`.\n",
    "Then run code visualizing TensorBoard again.\n",
    "* Notice what changed? Can you think of when this kind of thing is smart to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> Assignemnt 1: Your first TensorFlow op</span>\n",
    "For the first assignment you must implement Pythagoras' famous equation:\n",
    "$$c = \\sqrt{d^2 + e^2}$$\n",
    "\n",
    "You should create $a$ and $b$ as placeholders, and then compute $c$ for $d = {3, 2, 1}$ and $e = {4,5,6}$.\n",
    "\n",
    "It is **important** that you use TF ops for all the computations on the graph.\n",
    "(e.g. use `tf.square` instead of `np.square`)\n",
    "Otherwise TF can't optimize the code properly, and you risk it becoming VERY slow.\n",
    "You can find the TF math ops that you need [here](https://www.tensorflow.org/versions/r0.11/api_docs/python/math_ops/basic_math_functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e_values = [3,2,1]\n",
    "d_values = [4,5,6]\n",
    "\n",
    "## Your code here!\n",
    "# 1) Define the placeholders and the graph\n",
    "\n",
    "# 2) Start a session, and compute the output\n",
    "c_output = [0, 0, 0] # Use this variable name as your output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print out the results, and validate you get the correct values\n",
    "true_values = np.sqrt(np.square(e_values) + np.square(d_values))\n",
    "assingment_1_success = True\n",
    "\n",
    "for i in range(len(c_output)):\n",
    "    assingment_1_success = False if not np.abs(true_values[i] - c_output[i]) < 1e-6 else assingment_1_success\n",
    "    print('Corect value {:4.3f}, your value {:4.3f}. '.format(true_values[i], c_output[i]), end='')\n",
    "    if not assingment_1_success: \n",
    "        print(\"Oops :(\")\n",
    "        print(\"\\nSometihng went wrong, and the output isn't as expected.\\\n",
    "               \\nGo back and have a look, or ask someone for help.\")\n",
    "        break\n",
    "    print('Correct!')\n",
    "\n",
    "    \n",
    "if assingment_1_success:\n",
    "    print('\\nGood job! \\nTake a break, strecht your legs, and then continue onwards!')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini-assignment**:\n",
    "After having successfully completed the assignment go back and run the code TensorBoard visualization code again.\n",
    "* Did you remember to give your variables and placeholders meaningful names, or does everything look like a mess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Linear Regression\n",
    "\n",
    "Content\n",
    "* How to update the parameters using gradient descent\n",
    "* How to use TensorBoard to visualize the training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Credits\n",
    "Created by Toke Faurby ([faur](https://github.com/Faur)), based on previous work by \n",
    "* Lars Maaløe ([larsmaaloee](https://github.com/larsmaaloee))\n",
    "* Casper Sønderby ([casperkaae](https://github.com/casperkaae))\n",
    "* Søren Kaae Sønderby ([skaae](https://github.com/skaae))\n",
    "* Jonas Busk ([jonasbusk](https://github.com/jonasbusk))\n",
    "* Alexander R Johansen ([alrojo](https://github.com/alrojo))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
